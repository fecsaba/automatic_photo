{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fecsaba/automatic_photo/blob/main/auto_get_meta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_smXotz9jbOi"
      },
      "source": [
        "# **Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoHRxG5jfEhE",
        "outputId": "69fd6dec-9e42-4af0-be78-b70d4ad10b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting pypng\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypng\n",
            "Successfully installed pypng-0.20220715.0\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Csatoljuk a Google Drive-ot\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install pypng\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2TPdc1HkLVO"
      },
      "source": [
        "# ***Action***\n",
        "\n",
        "```\n",
        "'/content/drive/MyDrive/Images'\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wZ_Zmlc1g0W"
      },
      "source": [
        "## Meta kiszedése"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a3_Q8BBVaRr",
        "outputId": "df77e5e3-4e1e-4d9e-8e9f-be39da33bc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PNG fájlok keresése a következő mappában: /content/drive/MyDrive/Image/\n",
            "======================================================================\n",
            "\n",
            "Metaadatok a következő fájlhoz: ComfyUI_00001_ (2).png\n",
            "--------------------------------------------------\n",
            "**parameters**:\n",
            "A beautiful blonde woman walking in an urban city setting, her long hair flowing elegantly in the wind, soft natural lighting, cinematic composition, highly detailed facial features, photorealistic style with a touch of hyperrealism, dynamic motion capture, autumn leaves gently swirling around her, crisp and vibrant colors, 8k resolution, art by Greg Rutkowski and Loish. High detail on textures, sharp focus on the woman's face and hair, depth of field effect to emphasize the subject, warm golden hour tones, clean and polished finish, inspired by high-fashion photography and film stills. Ultra-detailed skin texture and lifelike eyes, Soft bokeh effects for lights in the background,perfection style, Cinematic Photography style,\n",
            "Negative prompt: \n",
            "Steps: 20, Sampler: euler_simple, Seed: 627362334615254, VAE: ae.safetensors, VAE hash: afc8e28272, Hashes: {\"vae\": \"afc8e28272\"}, Pos: A beautiful blonde woman walking in an urban city setting/ her long hair flowing elegantly in the wind/ soft natural lighting/ cinematic composition/ highly detailed facial features/ photorealistic style with a touch of hyperrealism/ dynamic motion capture/ autumn leaves gently swirling around her/ crisp and vibrant colors/ 8k resolution/ art by Greg Rutkowski and Loish. High detail on textures/ sharp focus on the woman's face and hair/ depth of field effect to emphasize the subject/ warm golden hour tones/ clean and polished finish/ inspired by high-fashion photography and film stills. Ultra-detailed skin texture and lifelike eyes/ Soft bokeh effects for lights in the background/perfection style/ Cinematic Photography style/\n",
            "\n",
            "**prompt**:\n",
            "{\"77\": {\"inputs\": {\"upscale_by\": 1.0, \"seed\": 627362334615254, \"steps\": 20, \"cfg\": 8.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.12, \"mode_type\": \"Linear\", \"tile_width\": [\"116\", 0], \"tile_height\": [\"116\", 1], \"mask_blur\": 8, \"tile_padding\": 32, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"99\", 0], \"model\": [\"110\", 0], \"positive\": [\"106\", 0], \"negative\": [\"100\", 0], \"vae\": [\"98\", 0], \"upscale_model\": [\"113\", 0]}, \"class_type\": \"UltimateSDUpscale\", \"_meta\": {\"title\": \"Ultimate SD Upscale\"}}, \"95\": {\"inputs\": {\"clip_name1\": \"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoaderGGUF\", \"_meta\": {\"title\": \"DualCLIPLoader (GGUF)\"}}, \"96\": {\"inputs\": {\"string\": \"perfection style, Cinematic Photography style,\"}, \"class_type\": \"Primitive string [Crystools]\", \"_meta\": {\"title\": \"Lora trigger\"}}, \"97\": {\"inputs\": {\"prompt1\": [\"107\", 0], \"prompt2\": [\"96\", 0], \"separator\": \",\"}, \"class_type\": \"easy promptConcat\", \"_meta\": {\"title\": \"PromptConcat\"}}, \"98\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\", \"_meta\": {\"title\": \"Load VAE\"}}, \"99\": {\"inputs\": {\"samples\": [\"108\", 0], \"vae\": [\"98\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"100\": {\"inputs\": {\"text\": [\"101\", 0], \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Negative (not used))\"}}, \"101\": {\"inputs\": {\"negative\": \"\"}, \"class_type\": \"easy negative\", \"_meta\": {\"title\": \"Negative\"}}, \"102\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"103\": {\"inputs\": {\"model\": [\"110\", 0], \"conditioning\": [\"106\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"104\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 20, \"denoise\": 1.0, \"model\": [\"110\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"105\": {\"inputs\": {\"noise_seed\": 627362334615254}, \"class_type\": \"RandomNoise\", \"_meta\": {\"title\": \"RandomNoise\"}}, \"106\": {\"inputs\": {\"text\": [\"97\", 0], \"clip\": [\"110\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"107\": {\"inputs\": {\"positive\": \"A beautiful blonde woman walking in an urban city setting, her long hair flowing elegantly in the wind, soft natural lighting, cinematic composition, highly detailed facial features, photorealistic style with a touch of hyperrealism, dynamic motion capture, autumn leaves gently swirling around her, crisp and vibrant colors, 8k resolution, art by Greg Rutkowski and Loish. High detail on textures, sharp focus on the woman's face and hair, depth of field effect to emphasize the subject, warm golden hour tones, clean and polished finish, inspired by high-fashion photography and film stills. Ultra-detailed skin texture and lifelike eyes, Soft bokeh effects for lights in the background\"}, \"class_type\": \"easy positive\", \"_meta\": {\"title\": \"Positive\"}}, \"108\": {\"inputs\": {\"noise\": [\"105\", 0], \"guider\": [\"103\", 0], \"sampler\": [\"102\", 0], \"sigmas\": [\"104\", 0], \"latent_image\": [\"109\", 0]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"109\": {\"inputs\": {\"width\": [\"116\", 0], \"height\": [\"116\", 1], \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\", \"_meta\": {\"title\": \"EmptySD3LatentImage\"}}, \"110\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1}, \"lora_2\": {\"on\": false, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1}, \"lora_3\": {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1}, \"\\u2795 Add Lora\": \"\", \"model\": [\"111\", 0], \"clip\": [\"95\", 0]}, \"class_type\": \"Power Lora Loader (rgthree)\", \"_meta\": {\"title\": \"Power Lora Loader (rgthree)\"}}, \"111\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q4_K_S.gguf\"}, \"class_type\": \"UnetLoaderGGUF\", \"_meta\": {\"title\": \"Unet Loader (GGUF)\"}}, \"112\": {\"inputs\": {\"images\": [\"99\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"113\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"115\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rghmp_00007_.png&type=temp&subfolder=&rand=0.5903458285284227\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rghmp_00008_.png&type=temp&subfolder=&rand=0.7928859180137502\"}]}, \"image_a\": [\"99\", 0], \"image_b\": [\"77\", 0]}, \"class_type\": \"Image Comparer (rgthree)\", \"_meta\": {\"title\": \"Image Comparer (rgthree)\"}}, \"116\": {\"inputs\": {\"megapixel\": \"1.0\", \"aspect_ratio\": \"9:16 (Slim Vertical)\", \"custom_ratio\": false, \"custom_aspect_ratio\": \"1:1\"}, \"class_type\": \"FluxResolutionNode\", \"_meta\": {\"title\": \"Flux Resolution Calc\"}}, \"117\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"sampler_selection_method\": \"Farthest\", \"sampler_selection_node_id\": 0, \"file_format\": \"png\", \"lossless_webp\": true, \"quality\": 100, \"save_workflow_json\": false, \"add_counter_to_filename\": true, \"civitai_sampler\": false, \"images\": [\"77\", 0], \"extra_metadata\": [\"118\", 0]}, \"class_type\": \"SaveImageWithMetaData\", \"_meta\": {\"title\": \"Save Image With Metadata\"}}, \"118\": {\"inputs\": {\"key1\": \"Pos\", \"value1\": [\"97\", 0], \"key2\": \"\", \"value2\": \"\", \"key3\": \"\", \"value3\": \"\", \"key4\": \"\", \"value4\": \"\"}, \"class_type\": \"CreateExtraMetaData\", \"_meta\": {\"title\": \"Create Extra MetaData\"}}, \"119\": {\"inputs\": {\"text\": \"{\\\"Pos\\\": \\\"A stunning blonde woman wearing light, flowing clothing appropriate for hot weather, confidently walking through a modern city located in a desert environment. The scene is set during the golden hour, with warm tones of orange and yellow lighting the landscape. Towering rugged mountains rise in the background, contrasting beautifully against the blue sky. The city architecture features contemporary designs adapted to the desert climate, with clean lines and reflective surfaces. The atmosphere conveys tranquility and warmth, with soft shadows stretching across the ground. Ultra-realistic style with sharp details, cinematic composition, 8k resolution,perfection style Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\", \"anything\": [\"118\", 0]}, \"class_type\": \"easy showAnything\", \"_meta\": {\"title\": \"Show Any\"}}}\n",
            "\n",
            "**workflow**:\n",
            "{\"last_node_id\": 119, \"last_link_id\": 170, \"nodes\": [{\"id\": 17, \"type\": \"easy showAnything\", \"pos\": [767.781982421875, -615.3192749023438], \"size\": [282.40643310546875, 210.21043395996094], \"flags\": {}, \"order\": 43, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 20}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [19], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A vivid portrayal of a woman standing beside a vintage car on a city street. She wears a sleek, shiny black bodysuit with a deep V-neckline, revealing her cleavage. Her blonde hair is styled in loose waves, and she wears a pearl necklace and red gloves. The car has a classic design with round headlights and a rounded front. The background shows a cityscape with tall buildings, street lamps, and a hazy atmosphere. The color palette is dominated by black, gold, and red, creating a striking contrast.\"]}, {\"id\": 15, \"type\": \"easy showAnything\", \"pos\": [1577.8197021484375, -372.9587097167969], \"size\": [262.2000427246094, 231.5201416015625], \"flags\": {}, \"order\": 53, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 18}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"ugly, watermark, ugly, watermark,\"]}, {\"id\": 26, \"type\": \"DualCLIPLoaderGGUF\", \"pos\": [-80.60908508300781, 1102.402587890625], \"size\": [315, 106], \"flags\": {}, \"order\": 0, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [36, 89], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoaderGGUF\"}, \"widgets_values\": [\"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 38, \"type\": \"Primitive string [Crystools]\", \"pos\": [-50.650367736816406, 1524.4832763671875], \"size\": [315, 58], \"flags\": {}, \"order\": 1, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"links\": [46]}], \"properties\": {\"Node name for S&R\": \"Primitive string [Crystools]\"}, \"widgets_values\": [\"perfection style, Cinematic Photography style,\"]}, {\"id\": 37, \"type\": \"easy promptConcat\", \"pos\": [-95.36030578613281, 1675.254638671875], \"size\": [315, 106], \"flags\": {}, \"order\": 31, \"mode\": 2, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt1\"}, \"link\": 45}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt2\"}, \"link\": 46}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [54], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 33, \"type\": \"VAELoader\", \"pos\": [1132.2061767578125, 1363.6859130859375], \"size\": [315, 58], \"flags\": {}, \"order\": 2, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [74], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 53, \"type\": \"VAEDecode\", \"pos\": [1152.6845703125, 1232.5308837890625], \"size\": [210, 46], \"flags\": {}, \"order\": 55, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 73}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 74}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [76], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 28, \"type\": \"CLIPTextEncode\", \"pos\": [367.1522521972656, 1277.09521484375], \"size\": [425.27801513671875, 180.6060791015625], \"flags\": {\"collapsed\": true}, \"order\": 30, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 36}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 55}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 41, \"type\": \"easy negative\", \"pos\": [402.1971130371094, 1332.6572265625], \"size\": [400, 200], \"flags\": {\"collapsed\": true}, \"order\": 3, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"negative\", \"type\": \"STRING\", \"links\": [55], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy negative\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 50, \"type\": \"KSamplerSelect\", \"pos\": [707.7028198242188, 1413.3487548828125], \"size\": [315, 58], \"flags\": {}, \"order\": 4, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [70]}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 54, \"type\": \"BasicGuider\", \"pos\": [729.659423828125, 1305.5447998046875], \"size\": [241.79998779296875, 46], \"flags\": {}, \"order\": 47, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 88}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 82}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [80]}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 45, \"type\": \"BasicScheduler\", \"pos\": [706.7091064453125, 1132.6806640625], \"size\": [315, 106], \"flags\": {}, \"order\": 40, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 87}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [81], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 1]}, {\"id\": 49, \"type\": \"RandomNoise\", \"pos\": [710.0362548828125, 1001.5338134765625], \"size\": [315, 82], \"flags\": {}, \"order\": 5, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [79]}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [627362334615247, \"fixed\"]}, {\"id\": 29, \"type\": \"CLIPTextEncode\", \"pos\": [372.3308410644531, 1226.7325439453125], \"size\": [422.84503173828125, 164.31304931640625], \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 90}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 54}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [82], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"closeup portrait of a sci-fi warrior robot, rusty metal, mech, cinematic, red eyes, dark interior background, movie scene, sharp, rim light, epic, golden hour\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 36, \"type\": \"easy positive\", \"pos\": [-82.27885437011719, 1264.1783447265625], \"size\": [400, 200], \"flags\": {}, \"order\": 6, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"links\": [45], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy positive\"}, \"widgets_values\": [\"A beautiful blonde woman with long flowing hair, wearing a light brown shirt and dark brown skirt, standing in a retro setting from the 1950s. The scene is brightly lit with soft natural lighting, highlighting her features. She has green necktie as an accessory. The overall style should be photorealistic yet slightly stylized to give it an artistic touch, similar to how images might appear in vintage magazines.\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 48, \"type\": \"SamplerCustomAdvanced\", \"pos\": [1077.8858642578125, 1016.5418701171875], \"size\": [355.20001220703125, 106], \"flags\": {}, \"order\": 51, \"mode\": 2, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 79}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 80}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 70}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 81}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 92}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [73], \"slot_index\": 0}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 57, \"type\": \"EmptySD3LatentImage\", \"pos\": [716.9642333984375, 1542.2567138671875], \"size\": [315, 106], \"flags\": {}, \"order\": 7, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [92], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 56, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": [322.69366455078125, 1005.2528076171875], \"size\": [340.20001220703125, 190], \"flags\": {}, \"order\": 32, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 86}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": 89}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [87, 88], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": [90]}], \"properties\": {\"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 34, \"type\": \"SaveImage\", \"pos\": [1510.758544921875, 1092.07080078125], \"size\": [415.8910827636719, 495.1932067871094], \"flags\": {}, \"order\": 58, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 76}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"0_lora\"]}, {\"id\": 27, \"type\": \"UnetLoaderGGUF\", \"pos\": [-57.48545837402344, 983.525390625], \"size\": [315, 58], \"flags\": {}, \"order\": 8, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [86], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q4_K_S.gguf\"]}, {\"id\": 59, \"type\": \"DualCLIPLoaderGGUF\", \"pos\": [-3.4884278774261475, 170.125], \"size\": [315, 106], \"flags\": {}, \"order\": 9, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [97, 110], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoaderGGUF\"}, \"widgets_values\": [\"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 62, \"type\": \"VAELoader\", \"pos\": [1209.326416015625, 431.40850830078125], \"size\": [315, 58], \"flags\": {}, \"order\": 10, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [96], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 66, \"type\": \"KSamplerSelect\", \"pos\": [784.8234252929688, 481.07122802734375], \"size\": [315, 58], \"flags\": {}, \"order\": 11, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [106]}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 67, \"type\": \"BasicGuider\", \"pos\": [806.7799682617188, 373.2672119140625], \"size\": [241.79998779296875, 46], \"flags\": {}, \"order\": 62, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 99}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 100}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [105]}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 69, \"type\": \"RandomNoise\", \"pos\": [787.1567993164062, 69.2560806274414], \"size\": [315, 82], \"flags\": {}, \"order\": 12, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [104]}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [627362334615247, \"fixed\"]}, {\"id\": 72, \"type\": \"SamplerCustomAdvanced\", \"pos\": [1155.0062255859375, 84.26424407958984], \"size\": [355.20001220703125, 106], \"flags\": {}, \"order\": 65, \"mode\": 2, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 104}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 105}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 106}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 107}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 108}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [95], \"slot_index\": 0}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 73, \"type\": \"EmptySD3LatentImage\", \"pos\": [794.0847778320312, 609.9793090820312], \"size\": [315, 106], \"flags\": {}, \"order\": 13, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [108], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 74, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": [399.81414794921875, 72.9750747680664], \"size\": [340.20001220703125, 190], \"flags\": {}, \"order\": 33, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 109}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": 110}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [99, 101], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": [102]}], \"properties\": {\"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 75, \"type\": \"UnetLoaderGGUF\", \"pos\": [19.63519859313965, 51.2474479675293], \"size\": [315, 58], \"flags\": {}, \"order\": 14, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [109], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q4_K_S.gguf\"]}, {\"id\": 19, \"type\": \"easy showAnything\", \"pos\": [1545.912841796875, -670.3446655273438], \"size\": [318.237548828125, 233.9617919921875], \"flags\": {}, \"order\": 52, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 21}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [113], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A vivid portrayal of a woman standing beside a vintage car on a city street. She wears a sleek, shiny black bodysuit with a deep V-neckline, revealing her cleavage. Her blonde hair is styled in loose waves, and she wears a pearl necklace and red gloves. The car has a classic design with round headlights and a rounded front. The background shows a cityscape with tall buildings, street lamps, and a hazy atmosphere. The color palette is dominated by black, gold, and red, creating a striking contrast..\"]}, {\"id\": 70, \"type\": \"CLIPTextEncode\", \"pos\": [360.617919921875, 335.9873962402344], \"size\": [422.84503173828125, 164.31304931640625], \"flags\": {\"collapsed\": true}, \"order\": 59, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 102}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 103}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [100], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"closeup portrait of a sci-fi warrior robot, rusty metal, mech, cinematic, red eyes, dark interior background, movie scene, sharp, rim light, epic, golden hour\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 64, \"type\": \"CLIPTextEncode\", \"pos\": [445.42633056640625, 465.9538879394531], \"size\": [425.27801513671875, 180.6060791015625], \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 97}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 98}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 61, \"type\": \"easy promptConcat\", \"pos\": [4.0260725021362305, 374.9734802246094], \"size\": [315, 106], \"flags\": {}, \"order\": 56, \"mode\": 2, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt1\"}, \"link\": 114}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt2\"}, \"link\": 113}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [103], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 60, \"type\": \"Primitive string [Crystools]\", \"pos\": [-9.293694496154785, 574.9005126953125], \"size\": [315, 58], \"flags\": {}, \"order\": 15, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"links\": [114], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Primitive string [Crystools]\"}, \"widgets_values\": [\"perfection style, Cinematic Photography style,\"]}, {\"id\": 65, \"type\": \"easy negative\", \"pos\": [457.1667175292969, 546.4353637695312], \"size\": [400, 200], \"flags\": {\"collapsed\": true}, \"order\": 16, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"negative\", \"type\": \"STRING\", \"links\": [98], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy negative\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 63, \"type\": \"VAEDecode\", \"pos\": [1229.8048095703125, 300.2533264160156], \"size\": [210, 46], \"flags\": {}, \"order\": 66, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 95}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 96}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [115], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 18, \"type\": \"LoadImage\", \"pos\": [-75.4588851928711, -676.1743774414062], \"size\": [315, 314], \"flags\": {}, \"order\": 17, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [16], \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"image.png\", \"image\"]}, {\"id\": 13, \"type\": \"Florence2Run\", \"pos\": [338.2167053222656, -567.7372436523438], \"size\": [400, 352], \"flags\": {}, \"order\": 35, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 16}, {\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"link\": 17}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1}, {\"name\": \"caption\", \"type\": \"STRING\", \"links\": [20], \"slot_index\": 2}, {\"name\": \"data\", \"type\": \"JSON\", \"links\": null, \"slot_index\": 3}], \"properties\": {\"Node name for S&R\": \"Florence2Run\"}, \"widgets_values\": [\"\", \"more_detailed_caption\", true, false, 1024, 3, true, \"\", 475282495362926, \"fixed\"]}, {\"id\": 14, \"type\": \"DownloadAndLoadFlorence2Model\", \"pos\": [-63.880775451660156, -279.4798583984375], \"size\": [365.4000244140625, 106], \"flags\": {}, \"order\": 18, \"mode\": 2, \"inputs\": [{\"name\": \"lora\", \"type\": \"PEFTLORA\", \"shape\": 7, \"link\": null}], \"outputs\": [{\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"links\": [17]}], \"properties\": {\"Node name for S&R\": \"DownloadAndLoadFlorence2Model\"}, \"widgets_values\": [\"thwri/CogFlorence-2.2-Large\", \"fp32\", \"sdpa\"]}, {\"id\": 16, \"type\": \"iToolsPromptStylerExtra\", \"pos\": [1098.371337890625, -658.1831665039062], \"size\": [300, 420], \"flags\": {}, \"order\": 48, \"mode\": 2, \"inputs\": [{\"name\": \"text_positive\", \"type\": \"STRING\", \"widget\": {\"name\": \"text_positive\"}, \"link\": 19}], \"outputs\": [{\"name\": \"positive_prompt\", \"type\": \"STRING\", \"links\": [21], \"slot_index\": 0}, {\"name\": \"negative_prompt\", \"type\": \"STRING\", \"links\": [18], \"slot_index\": 1}, {\"name\": \"used_templates\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"iToolsPromptStylerExtra\"}, \"widgets_values\": [\"\", \"ugly, watermark\", \"Drawing.yaml\", \"none\", \"Art.yaml\", \"none\", \"artist.yaml\", \"none\", \"mood.yaml\", \"none\", null], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 68, \"type\": \"BasicScheduler\", \"pos\": [783.8296508789062, 200.40298461914062], \"size\": [315, 106], \"flags\": {}, \"order\": 42, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 101}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [107], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 0.89]}, {\"id\": 76, \"type\": \"SaveImage\", \"pos\": [1561.0301513671875, 94.03004455566406], \"size\": [315, 270], \"flags\": {}, \"order\": 67, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 115}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"den_0.89\"]}, {\"id\": 111, \"type\": \"UnetLoaderGGUF\", \"pos\": [-268.4195861816406, 1940.0777587890625], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q4_K_S.gguf\"]}, {\"id\": 95, \"type\": \"DualCLIPLoaderGGUF\", \"pos\": [-270.7694396972656, 1992.3370361328125], \"size\": [315, 106], \"flags\": {\"collapsed\": true}, \"order\": 20, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [139, 152], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoaderGGUF\"}, \"widgets_values\": [\"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 101, \"type\": \"easy negative\", \"pos\": [-78.7986831665039, 2418.867919921875], \"size\": [400, 200], \"flags\": {\"collapsed\": true}, \"order\": 21, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"negative\", \"type\": \"STRING\", \"links\": [140], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy negative\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 106, \"type\": \"CLIPTextEncode\", \"pos\": [159.29617309570312, 2172.989013671875], \"size\": [422.84503173828125, 164.31304931640625], \"flags\": {\"collapsed\": true}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 144}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 145}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [142, 156], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"closeup portrait of a sci-fi warrior robot, rusty metal, mech, cinematic, red eyes, dark interior background, movie scene, sharp, rim light, epic, golden hour\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 100, \"type\": \"CLIPTextEncode\", \"pos\": [165.4341583251953, 2219.774169921875], \"size\": [425.27801513671875, 180.6060791015625], \"flags\": {\"collapsed\": true}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 139}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 140}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0}], \"title\": \"Negative (not used))\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 104, \"type\": \"BasicScheduler\", \"pos\": [523.7125244140625, 2064.162841796875], \"size\": [315, 106], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 143}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [149], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 1]}, {\"id\": 103, \"type\": \"BasicGuider\", \"pos\": [530.9034423828125, 2220.55029296875], \"size\": [241.79998779296875, 46], \"flags\": {\"collapsed\": true}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 141}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 142}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [147]}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 102, \"type\": \"KSamplerSelect\", \"pos\": [534.735107421875, 2273.911865234375], \"size\": [315, 58], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [148]}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 109, \"type\": \"EmptySD3LatentImage\", \"pos\": [538.982177734375, 2377.75], \"size\": [315, 106], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"widget\": {\"name\": \"width\"}, \"link\": 163}, {\"name\": \"height\", \"type\": \"INT\", \"widget\": {\"name\": \"height\"}, \"link\": 164}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 116, \"type\": \"FluxResolutionNode\", \"pos\": [154.09820556640625, 2268.203369140625], \"size\": [315, 190], \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [163, 166], \"slot_index\": 0}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [164, 165], \"slot_index\": 1}, {\"name\": \"resolution\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"preview\", \"type\": \"IMAGE\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"FluxResolutionNode\"}, \"widgets_values\": [\"1.0\", \"9:16 (Slim Vertical)\", false, \"1:1\"]}, {\"id\": 105, \"type\": \"RandomNoise\", \"pos\": [520.5926513671875, 1935.8798828125], \"size\": [315, 82], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [146]}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [627362334615254, \"increment\"]}, {\"id\": 110, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": [154.74021911621094, 1935.301025390625], \"size\": [340.20001220703125, 190], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 151}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": 152}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [141, 143, 155], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": [144]}], \"properties\": {\"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 42, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": [-479.51715087890625, -338.01678466796875], \"size\": [226.8000030517578, 130], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}}, {\"id\": 112, \"type\": \"PreviewImage\", \"pos\": [873.8810424804688, 2228.5751953125], \"size\": [210, 246], \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 153}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 98, \"type\": \"VAELoader\", \"pos\": [884.990478515625, 2151.964111328125], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 26, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [138, 158], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 99, \"type\": \"VAEDecode\", \"pos\": [886.0210571289062, 2078.761474609375], \"size\": [210, 46], \"flags\": {\"collapsed\": true}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 137}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 138}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [153, 154, 161], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 108, \"type\": \"SamplerCustomAdvanced\", \"pos\": [858.0021362304688, 1938.1632080078125], \"size\": [355.20001220703125, 106], \"flags\": {\"collapsed\": false}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 146}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 147}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 148}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 149}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 150}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [137], \"slot_index\": 0}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 97, \"type\": \"easy promptConcat\", \"pos\": [-257.70318603515625, 2418.441650390625], \"size\": [315, 106], \"flags\": {\"collapsed\": false}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt1\"}, \"link\": 135}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt2\"}, \"link\": 136}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [145, 168], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 77, \"type\": \"UltimateSDUpscale\", \"pos\": [1491.6929931640625, 1929.3623046875], \"size\": [315, 614], \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 154}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 155}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 156}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 157}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 158}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 159}, {\"name\": \"tile_width\", \"type\": \"INT\", \"widget\": {\"name\": \"tile_width\"}, \"link\": 166}, {\"name\": \"tile_height\", \"type\": \"INT\", \"widget\": {\"name\": \"tile_height\"}, \"link\": 165}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [162, 169], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1, 627362334615254, \"increment\", 20, 8, \"euler\", \"normal\", 0.12, \"Linear\", 512, 512, 8, 32, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 115, \"type\": \"Image Comparer (rgthree)\", \"pos\": [2015.6654052734375, 2027.52099609375], \"size\": [712.5426635742188, 808.9713745117188], \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 161}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 162}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rghmp_00007_.png&type=temp&subfolder=&rand=0.5903458285284227\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rghmp_00008_.png&type=temp&subfolder=&rand=0.7928859180137502\"}]]}, {\"id\": 118, \"type\": \"CreateExtraMetaData\", \"pos\": [498.58355712890625, 2539.094482421875], \"size\": [367.79998779296875, 226], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": null}, {\"name\": \"value1\", \"type\": \"STRING\", \"widget\": {\"name\": \"value1\"}, \"link\": 168}], \"outputs\": [{\"name\": \"EXTRA_METADATA\", \"type\": \"EXTRA_METADATA\", \"links\": [167, 170], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CreateExtraMetaData\"}, \"widgets_values\": [\"Pos\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]}, {\"id\": 119, \"type\": \"easy showAnything\", \"pos\": [889.2656860351562, 2572.42724609375], \"size\": [239.81918334960938, 357.0870361328125], \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 170}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [[\"{\\\"Pos\\\": \\\"A beautiful blonde woman walking in an urban city setting, her long hair flowing elegantly in the wind, soft natural lighting, cinematic composition, highly detailed facial features, photorealistic style with a touch of hyperrealism, dynamic motion capture, autumn leaves gently swirling around her, crisp and vibrant colors, 8k resolution, art by Greg Rutkowski and Loish. High detail on textures, sharp focus on the woman's face and hair, depth of field effect to emphasize the subject, warm golden hour tones, clean and polished finish, inspired by high-fashion photography and film stills. Ultra-detailed skin texture and lifelike eyes, Soft bokeh effects for lights in the background,perfection style, Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\"]]}, {\"id\": 117, \"type\": \"SaveImageWithMetaData\", \"pos\": [1142.363037109375, 2214.53564453125], \"size\": [315, 482], \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 169}, {\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": 167}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageWithMetaData\"}, \"widgets_values\": [\"ComfyUI\", \"Farthest\", 0, \"png\", true, 100, false, true, false]}, {\"id\": 96, \"type\": \"Primitive string [Crystools]\", \"pos\": [-256.570068359375, 2296.220458984375], \"size\": [315, 58], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"links\": [136]}], \"title\": \"Lora trigger\", \"properties\": {\"Node name for S&R\": \"Primitive string [Crystools]\"}, \"widgets_values\": [\"perfection style, Cinematic Photography style,\"]}, {\"id\": 113, \"type\": \"UpscaleModelLoader\", \"pos\": [1117.623779296875, 2129.073974609375], \"size\": [315, 58], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [159]}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 107, \"type\": \"easy positive\", \"pos\": [-265.27569580078125, 2043.079345703125], \"size\": [400, 200], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"links\": [135], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"easy positive\"}, \"widgets_values\": [\"A beautiful blonde woman walking in an urban city setting, her long hair flowing elegantly in the wind, soft natural lighting, cinematic composition, highly detailed facial features, photorealistic style with a touch of hyperrealism, dynamic motion capture, autumn leaves gently swirling around her, crisp and vibrant colors, 8k resolution, art by Greg Rutkowski and Loish. High detail on textures, sharp focus on the woman's face and hair, depth of field effect to emphasize the subject, warm golden hour tones, clean and polished finish, inspired by high-fashion photography and film stills. Ultra-detailed skin texture and lifelike eyes, Soft bokeh effects for lights in the background\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[16, 18, 0, 13, 0, \"IMAGE\"], [17, 14, 0, 13, 1, \"FL2MODEL\"], [18, 16, 1, 15, 0, \"*\"], [19, 17, 0, 16, 0, \"STRING\"], [20, 13, 2, 17, 0, \"*\"], [21, 16, 0, 19, 0, \"*\"], [36, 26, 0, 28, 0, \"CLIP\"], [45, 36, 0, 37, 0, \"STRING\"], [46, 38, 0, 37, 1, \"STRING\"], [54, 37, 0, 29, 1, \"STRING\"], [55, 41, 0, 28, 1, \"STRING\"], [70, 50, 0, 48, 2, \"SAMPLER\"], [73, 48, 0, 53, 0, \"LATENT\"], [74, 33, 0, 53, 1, \"VAE\"], [76, 53, 0, 34, 0, \"IMAGE\"], [79, 49, 0, 48, 0, \"NOISE\"], [80, 54, 0, 48, 1, \"GUIDER\"], [81, 45, 0, 48, 3, \"SIGMAS\"], [82, 29, 0, 54, 1, \"CONDITIONING\"], [86, 27, 0, 56, 0, \"MODEL\"], [87, 56, 0, 45, 0, \"MODEL\"], [88, 56, 0, 54, 0, \"MODEL\"], [89, 26, 0, 56, 1, \"CLIP\"], [90, 56, 1, 29, 0, \"CLIP\"], [92, 57, 0, 48, 4, \"LATENT\"], [95, 72, 0, 63, 0, \"LATENT\"], [96, 62, 0, 63, 1, \"VAE\"], [97, 59, 0, 64, 0, \"CLIP\"], [98, 65, 0, 64, 1, \"STRING\"], [99, 74, 0, 67, 0, \"MODEL\"], [100, 70, 0, 67, 1, \"CONDITIONING\"], [101, 74, 0, 68, 0, \"MODEL\"], [102, 74, 1, 70, 0, \"CLIP\"], [103, 61, 0, 70, 1, \"STRING\"], [104, 69, 0, 72, 0, \"NOISE\"], [105, 67, 0, 72, 1, \"GUIDER\"], [106, 66, 0, 72, 2, \"SAMPLER\"], [107, 68, 0, 72, 3, \"SIGMAS\"], [108, 73, 0, 72, 4, \"LATENT\"], [109, 75, 0, 74, 0, \"MODEL\"], [110, 59, 0, 74, 1, \"CLIP\"], [113, 19, 0, 61, 1, \"STRING\"], [114, 60, 0, 61, 0, \"STRING\"], [115, 63, 0, 76, 0, \"IMAGE\"], [135, 107, 0, 97, 0, \"STRING\"], [136, 96, 0, 97, 1, \"STRING\"], [137, 108, 0, 99, 0, \"LATENT\"], [138, 98, 0, 99, 1, \"VAE\"], [139, 95, 0, 100, 0, \"CLIP\"], [140, 101, 0, 100, 1, \"STRING\"], [141, 110, 0, 103, 0, \"MODEL\"], [142, 106, 0, 103, 1, \"CONDITIONING\"], [143, 110, 0, 104, 0, \"MODEL\"], [144, 110, 1, 106, 0, \"CLIP\"], [145, 97, 0, 106, 1, \"STRING\"], [146, 105, 0, 108, 0, \"NOISE\"], [147, 103, 0, 108, 1, \"GUIDER\"], [148, 102, 0, 108, 2, \"SAMPLER\"], [149, 104, 0, 108, 3, \"SIGMAS\"], [150, 109, 0, 108, 4, \"LATENT\"], [151, 111, 0, 110, 0, \"MODEL\"], [152, 95, 0, 110, 1, \"CLIP\"], [153, 99, 0, 112, 0, \"IMAGE\"], [154, 99, 0, 77, 0, \"IMAGE\"], [155, 110, 0, 77, 1, \"MODEL\"], [156, 106, 0, 77, 2, \"CONDITIONING\"], [157, 100, 0, 77, 3, \"CONDITIONING\"], [158, 98, 0, 77, 4, \"VAE\"], [159, 113, 0, 77, 5, \"UPSCALE_MODEL\"], [161, 99, 0, 115, 0, \"IMAGE\"], [162, 77, 0, 115, 1, \"IMAGE\"], [163, 116, 0, 109, 0, \"INT\"], [164, 116, 1, 109, 1, \"INT\"], [165, 116, 1, 77, 7, \"INT\"], [166, 116, 0, 77, 6, \"INT\"], [167, 118, 0, 117, 1, \"EXTRA_METADATA\"], [168, 97, 0, 118, 1, \"STRING\"], [169, 77, 0, 117, 0, \"IMAGE\"], [170, 118, 0, 119, 0, \"*\"]], \"groups\": [{\"id\": 1, \"title\": \"GGUF\", \"bounding\": [-132.03518676757812, -749.7743530273438, 2112.071533203125, 1571.5823974609375], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"id\": 2, \"title\": \"TXT2IMG\", \"bounding\": [-105.36031341552734, 909.9256591796875, 2042.0096435546875, 881.3292846679688], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"id\": 3, \"title\": \"TXT2IMG Upscale\", \"bounding\": [-280.7694396972656, 1855.7623291015625, 3018.9775390625, 1083.7518310546875], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.1, \"offset\": {\"0\": 295.2647399902344, \"1\": -1977.656005859375}}, \"node_versions\": {\"ComfyUI-Easy-Use\": \"aadbb0b38945eba3e15be6099a7f4e5c0327c175\", \"ComfyUI-GGUF\": \"5875c52f59baca3a9372d68c43a3775e21846fe0\", \"ComfyUI-Crystools\": \"72e2e9af4a6b9a58ca5d753cacff37ba1ff9bfa8\", \"comfy-core\": \"0.3.14\", \"rgthree-comfy\": \"31b784bac495160436a8cd91bf1a856cf01a738e\", \"ComfyUI-Florence2\": \"90b012e922f8bb0482bcd2ae24cdc191ec12a11f\", \"ComfyUI-iTools\": \"c1847d1aa6115bf52fec2440fa5a235235d1477f\", \"ControlAltAI-Nodes\": \"404b22d09283b2ece48da6c4e024d4d6beaecb07\", \"ComfyUI_UltimateSDUpscale\": \"ff3fdfeee03de46d4462211cffd165d27155e858\", \"ComfyUI-SaveImageWithMetaData\": \"dc9990fc20c1a8c4041cb090f07b1ffe5cb21cf2\"}}, \"version\": 0.4, \"seed_widgets\": {\"13\": 8, \"49\": 0, \"69\": 0, \"77\": 1, \"105\": 0}, \"widget_idx_map\": {\"13\": {\"seed\": 8}, \"45\": {\"scheduler\": 0}, \"49\": {\"noise_seed\": 0}, \"50\": {\"sampler_name\": 0}, \"66\": {\"sampler_name\": 0}, \"68\": {\"scheduler\": 0}, \"69\": {\"noise_seed\": 0}, \"77\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"102\": {\"sampler_name\": 0}, \"104\": {\"scheduler\": 0}, \"105\": {\"noise_seed\": 0}}}\n",
            "\n",
            "\n",
            "Metaadatok a következő fájlhoz: ComfyUI_00005_.png\n",
            "--------------------------------------------------\n",
            "**parameters**:\n",
            "A white cat with striking bright green eyes peeking out from behind a torn piece of paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain white background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.,perfection style, Cinematic Photography style,\n",
            "Negative prompt: \n",
            "Steps: 20, Sampler: euler_simple, Seed: 257208041668693, VAE: ae.safetensors, VAE hash: afc8e28272, Lora_0 Model name: Stock_Footage_Style_XL_F1D.safetensors, Lora_0 Model hash: 29a06a259b, Lora_0 Strength model: 1, Lora_0 Strength clip: 1, Hashes: {\"vae\": \"afc8e28272\", \"lora:Stock_Footage_Style_XL_F1D\": \"29a06a259b\"}, Pos: A white cat with striking bright green eyes peeking out from behind a torn piece of paper/ highly detailed fur texture/ soft lighting/ playful and curious expression/ visible paws in a playful pose/ realistic and lifelike/ set against a plain white background/ ultra-detailed whiskers and claws/ photorealistic style/ 8k resolution/ art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth./perfection style/ Cinematic Photography style/\n",
            "\n",
            "**prompt**:\n",
            "{\"95\": {\"inputs\": {\"clip_name1\": \"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoaderGGUF\", \"_meta\": {\"title\": \"DualCLIPLoader (GGUF)\"}}, \"96\": {\"inputs\": {\"string\": \"perfection style, Cinematic Photography style,\"}, \"class_type\": \"Primitive string [Crystools]\", \"_meta\": {\"title\": \"Lora trigger\"}}, \"97\": {\"inputs\": {\"prompt1\": [\"107\", 0], \"prompt2\": [\"96\", 0], \"separator\": \",\"}, \"class_type\": \"easy promptConcat\", \"_meta\": {\"title\": \"PromptConcat\"}}, \"98\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\", \"_meta\": {\"title\": \"Load VAE\"}}, \"99\": {\"inputs\": {\"samples\": [\"108\", 0], \"vae\": [\"98\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"100\": {\"inputs\": {\"text\": [\"141\", 19], \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Negative (not used))\"}}, \"101\": {\"inputs\": {\"negative\": \"\"}, \"class_type\": \"easy negative\", \"_meta\": {\"title\": \"Negative\"}}, \"102\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"103\": {\"inputs\": {\"model\": [\"110\", 0], \"conditioning\": [\"106\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"104\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 20, \"denoise\": 0.9500000000000001, \"model\": [\"110\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"105\": {\"inputs\": {\"noise_seed\": 257208041668693}, \"class_type\": \"RandomNoise\", \"_meta\": {\"title\": \"RandomNoise\"}}, \"106\": {\"inputs\": {\"text\": [\"141\", 17], \"clip\": [\"110\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"107\": {\"inputs\": {\"positive\": \"A white cat with striking bright green eyes peeking out from behind a torn piece of paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain white background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.\"}, \"class_type\": \"easy positive\", \"_meta\": {\"title\": \"Positive\"}}, \"108\": {\"inputs\": {\"noise\": [\"105\", 0], \"guider\": [\"103\", 0], \"sampler\": [\"102\", 0], \"sigmas\": [\"104\", 0], \"latent_image\": [\"109\", 0]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"109\": {\"inputs\": {\"width\": [\"116\", 0], \"height\": [\"116\", 1], \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\", \"_meta\": {\"title\": \"EmptySD3LatentImage\"}}, \"110\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1}, \"lora_2\": {\"on\": true, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1}, \"lora_3\": {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1}, \"\\u2795 Add Lora\": \"\", \"model\": [\"111\", 0], \"clip\": [\"95\", 0]}, \"class_type\": \"Power Lora Loader (rgthree)\", \"_meta\": {\"title\": \"Power Lora Loader (rgthree)\"}}, \"111\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q4_K_S.gguf\"}, \"class_type\": \"UnetLoaderGGUF\", \"_meta\": {\"title\": \"Unet Loader (GGUF)\"}}, \"112\": {\"inputs\": {\"images\": [\"99\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"113\": {\"inputs\": {\"model_name\": \"ESRGAN_4x.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"116\": {\"inputs\": {\"megapixel\": \"1.0\", \"aspect_ratio\": \"9:16 (Slim Vertical)\", \"custom_ratio\": false, \"custom_aspect_ratio\": \"1:1\"}, \"class_type\": \"FluxResolutionNode\", \"_meta\": {\"title\": \"Flux Resolution Calc\"}}, \"117\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"sampler_selection_method\": \"Farthest\", \"sampler_selection_node_id\": 0, \"file_format\": \"png\", \"lossless_webp\": true, \"quality\": 100, \"save_workflow_json\": false, \"add_counter_to_filename\": true, \"civitai_sampler\": false, \"images\": [\"152\", 7], \"extra_metadata\": [\"118\", 0]}, \"class_type\": \"SaveImageWithMetaData\", \"_meta\": {\"title\": \"Save Image With Metadata\"}}, \"118\": {\"inputs\": {\"key1\": \"Pos\", \"value1\": [\"152\", 17], \"key2\": \"\", \"value2\": \"\", \"key3\": \"\", \"value3\": \"\", \"key4\": \"\", \"value4\": \"\"}, \"class_type\": \"CreateExtraMetaData\", \"_meta\": {\"title\": \"Create Extra MetaData\"}}, \"119\": {\"inputs\": {\"text\": \"{\\\"Pos\\\": \\\"A white cat with striking bright green eyes peeking out from behind a black piece of textile or fabric. Highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike appearance. Plain white background to highlight the cat and its interaction with the textile. Ultra-detailed whiskers and claws, photorealistic style, 8K resolution, art inspired by Albert Hirai and David Revoy. The texture and structure of the textile are clearly visible, with frayed or worn edges. Soft bokeh effect in the background to keep the focus on the cat. Minimalist design to better emphasize the subject. ,perfection style, Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\", \"anything\": [\"118\", 0]}, \"class_type\": \"easy showAnything\", \"_meta\": {\"title\": \"Show Any\"}}, \"121\": {\"inputs\": {\"text_pos_g\": [\"97\", 0], \"text_neg_g\": [\"101\", 0]}, \"class_type\": \"Context Big (rgthree)\", \"_meta\": {\"title\": \"Context Big (rgthree)\"}}, \"141\": {\"inputs\": {\"ctx_01\": [\"121\", 0]}, \"class_type\": \"Context Switch Big (rgthree)\", \"_meta\": {\"title\": \"Context Switch Big (rgthree)\"}}, \"149\": {\"inputs\": {\"model\": [\"110\", 0], \"vae\": [\"98\", 0], \"positive\": [\"106\", 0], \"negative\": [\"100\", 0], \"images\": [\"99\", 0], \"text_pos_g\": [\"141\", 17]}, \"class_type\": \"Context Big (rgthree)\", \"_meta\": {\"title\": \"Context Big (rgthree)\"}}, \"152\": {\"inputs\": {\"ctx_01\": [\"149\", 0]}, \"class_type\": \"Context Merge Big (rgthree)\", \"_meta\": {\"title\": \"Context Merge Big (rgthree)\"}}, \"153\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00013_.png&type=temp&subfolder=&rand=0.7204508324421925\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00014_.png&type=temp&subfolder=&rand=0.4616699002496001\"}]}, \"image_a\": [\"152\", 7], \"image_b\": [\"99\", 0]}, \"class_type\": \"Image Comparer (rgthree)\", \"_meta\": {\"title\": \"Image Comparer (rgthree)\"}}}\n",
            "\n",
            "**workflow**:\n",
            "{\"last_node_id\": 158, \"last_link_id\": 240, \"nodes\": [{\"id\": 116, \"type\": \"FluxResolutionNode\", \"pos\": [-85.54752349853516, 2331.3125], \"size\": [315, 190], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [163], \"slot_index\": 0}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [164], \"slot_index\": 1}, {\"name\": \"resolution\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"preview\", \"type\": \"IMAGE\", \"links\": null}], \"properties\": {\"cnr_id\": \"controlaltai-nodes\", \"ver\": \"404b22d09283b2ece48da6c4e024d4d6beaecb07\", \"Node name for S&R\": \"FluxResolutionNode\"}, \"widgets_values\": [\"1.0\", \"9:16 (Slim Vertical)\", false, \"1:1\"]}, {\"id\": 96, \"type\": \"Primitive string [Crystools]\", \"pos\": [-1716.4249267578125, 2209.827392578125], \"size\": [315, 58], \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"links\": [136]}], \"title\": \"Lora trigger\", \"properties\": {\"cnr_id\": \"comfyui-crystools\", \"ver\": \"72e2e9af4a6b9a58ca5d753cacff37ba1ff9bfa8\", \"Node name for S&R\": \"Primitive string [Crystools]\"}, \"widgets_values\": [\"perfection style, Cinematic Photography style,\"]}, {\"id\": 103, \"type\": \"BasicGuider\", \"pos\": [291.2577209472656, 2283.659423828125], \"size\": [241.79998779296875, 46], \"flags\": {\"collapsed\": false}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 141}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 142}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [147]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 109, \"type\": \"EmptySD3LatentImage\", \"pos\": [302.2720642089844, 2504.952880859375], \"size\": [315, 106], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"widget\": {\"name\": \"width\"}, \"link\": 163}, {\"name\": \"height\", \"type\": \"INT\", \"widget\": {\"name\": \"height\"}, \"link\": 164}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 102, \"type\": \"KSamplerSelect\", \"pos\": [295.0891418457031, 2391.32861328125], \"size\": [315, 58], \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [148]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 95, \"type\": \"DualCLIPLoaderGGUF\", \"pos\": [-333.3307800292969, 2075.8251953125], \"size\": [315, 106], \"flags\": {\"collapsed\": true}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [139, 152], \"slot_index\": 0}], \"properties\": {\"aux_id\": \"city96/ComfyUI-GGUF\", \"ver\": \"e024aab10d0444dcaf88d7abec3ab98a62b66043\", \"Node name for S&R\": \"DualCLIPLoaderGGUF\"}, \"widgets_values\": [\"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 111, \"type\": \"UnetLoaderGGUF\", \"pos\": [-322.04339599609375, 2136.907958984375], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"aux_id\": \"city96/ComfyUI-GGUF\", \"ver\": \"e024aab10d0444dcaf88d7abec3ab98a62b66043\", \"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q4_K_S.gguf\"]}, {\"id\": 139, \"type\": \"easy showAnything\", \"pos\": [-975.3072509765625, 925.1323852539062], \"size\": [318.237548828125, 233.9617919921875], \"flags\": {}, \"order\": 27, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 196}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [202], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A close-up of a person wearing a black t-shirt with a graphic design on the front. The design features a white cat with striking green eyes peeking out from behind a torn piece of paper. The cat's paws are visible, and it appears to be in a playful pose. The person wears a gold necklace and a silver watch on their wrist. The background is plain white, highlighting the cat and the person's clothing..\"]}, {\"id\": 135, \"type\": \"easy showAnything\", \"pos\": [-943.4004516601562, 1222.51806640625], \"size\": [262.2000427246094, 231.5201416015625], \"flags\": {}, \"order\": 28, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 197}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [203], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"ugly, watermark, ugly, watermark,\"]}, {\"id\": 144, \"type\": \"Reroute (rgthree)\", \"pos\": [-461.2772216796875, 1088.3099365234375], \"size\": [40, 30], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 204, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [205], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30]}}, {\"id\": 143, \"type\": \"Context Big (rgthree)\", \"pos\": [-1128.98779296875, 1400.7568359375], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 29, \"mode\": 2, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 202}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 203}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [204], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 134, \"type\": \"DownloadAndLoadFlorence2Model\", \"pos\": [-2585.100830078125, 1315.996826171875], \"size\": [365.4000244140625, 106], \"flags\": {}, \"order\": 5, \"mode\": 2, \"inputs\": [{\"name\": \"lora\", \"type\": \"PEFTLORA\", \"shape\": 7, \"link\": null}], \"outputs\": [{\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"links\": [193], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-florence2\", \"ver\": \"1.0.3\", \"Node name for S&R\": \"DownloadAndLoadFlorence2Model\"}, \"widgets_values\": [\"thwri/CogFlorence-2.2-Large\", \"fp16\", \"sdpa\"]}, {\"id\": 124, \"type\": \"Reroute (rgthree)\", \"pos\": [-536.951171875, 1944.7838134765625], \"size\": [40, 30], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 210, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [198], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 101, \"type\": \"easy negative\", \"pos\": [-1296.494873046875, 1946.167236328125], \"size\": [400, 200], \"flags\": {\"collapsed\": false}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"negative\", \"type\": \"STRING\", \"links\": [176], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy negative\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 121, \"type\": \"Context Big (rgthree)\", \"pos\": [-1206.7908935546875, 2194.957763671875], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 177}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 176}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [210], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 97, \"type\": \"easy promptConcat\", \"pos\": [-1203.9688720703125, 2245.002197265625], \"size\": [315, 106], \"flags\": {\"collapsed\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt1\"}, \"link\": 135}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt2\"}, \"link\": 136}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [177], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 112, \"type\": \"PreviewImage\", \"pos\": [685.3842163085938, 2321.6806640625], \"size\": [210, 246], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 153}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 106, \"type\": \"CLIPTextEncode\", \"pos\": [-24.871721267700195, 2225.4462890625], \"size\": [422.84503173828125, 164.31304931640625], \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 209}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 199}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [142, 213], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"closeup portrait of a sci-fi warrior robot, rusty metal, mech, cinematic, red eyes, dark interior background, movie scene, sharp, rim light, epic, golden hour\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 100, \"type\": \"CLIPTextEncode\", \"pos\": [-25.847551345825195, 2271.742919921875], \"size\": [425.27801513671875, 180.6060791015625], \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 139}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 200}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [214], \"slot_index\": 0}], \"title\": \"Negative (not used))\", \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 98, \"type\": \"VAELoader\", \"pos\": [645.3443603515625, 2215.0732421875], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [138, 215], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 145, \"type\": \"Reroute (rgthree)\", \"pos\": [-354.1865539550781, 1744.037109375], \"size\": [40, 30], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 205, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [206], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 118, \"type\": \"CreateExtraMetaData\", \"pos\": [1982.21728515625, 2609.320556640625], \"size\": [367.79998779296875, 226], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": null}, {\"name\": \"value1\", \"type\": \"STRING\", \"widget\": {\"name\": \"value1\"}, \"link\": 225}], \"outputs\": [{\"name\": \"EXTRA_METADATA\", \"type\": \"EXTRA_METADATA\", \"links\": [167, 170], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"CreateExtraMetaData\"}, \"widgets_values\": [\"Pos\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]}, {\"id\": 119, \"type\": \"easy showAnything\", \"pos\": [2408.923583984375, 2572.09814453125], \"size\": [239.81918334960938, 357.0870361328125], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 170}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": null}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [[\"{\\\"Pos\\\": \\\"A white cat with striking bright green eyes peeking out from behind a torn piece of paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain white background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.,perfection style, Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\"]]}, {\"id\": 152, \"type\": \"Context Merge Big (rgthree)\", \"pos\": [1578.6474609375, 2086.99560546875], \"size\": [226.8000030517578, 466], \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"ctx_01\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 217}, {\"name\": \"ctx_02\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_03\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_04\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_05\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [220], \"slot_index\": 1}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": [223], \"slot_index\": 3}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": [221], \"slot_index\": 4}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": [222], \"slot_index\": 5}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": [219], \"slot_index\": 7}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [225], \"slot_index\": 17}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 42, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": [-114.01629638671875, 868.0133056640625], \"size\": [226.8000030517578, 202], \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}}, {\"id\": 113, \"type\": \"UpscaleModelLoader\", \"pos\": [1529.2525634765625, 1965.1983642578125], \"size\": [315, 58], \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [159], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"ESRGAN_4x.pth\"]}, {\"id\": 99, \"type\": \"VAEDecode\", \"pos\": [686.040283203125, 2142.46142578125], \"size\": [210, 46], \"flags\": {\"collapsed\": false}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 137}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 138}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [153, 211, 232], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 77, \"type\": \"UltimateSDUpscale\", \"pos\": [1918.5362548828125, 1951.04296875], \"size\": [315, 614], \"flags\": {}, \"order\": 42, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 219}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 220}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 221}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 222}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 223}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 159}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [169, 231], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui_ultimatesdupscale\", \"ver\": \"ff3fdfeee03de46d4462211cffd165d27155e858\", \"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [4, 627362334615287, \"increment\", 20, 1, \"euler\", \"normal\", 0.12, \"Linear\", 512, 512, 8, 0, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 153, \"type\": \"Image Comparer (rgthree)\", \"pos\": [846.02734375, 2832.2861328125], \"size\": [663.0813598632812, 731.4021606445312], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 231}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 232}], \"outputs\": [], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\", \"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00013_.png&type=temp&subfolder=&rand=0.7204508324421925\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00014_.png&type=temp&subfolder=&rand=0.4616699002496001\"}]]}, {\"id\": 138, \"type\": \"LoadImage\", \"pos\": [-2596.678955078125, 919.302734375], \"size\": [315, 314], \"flags\": {}, \"order\": 10, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [192], \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"K\\u00e9perny\\u0151k\\u00e9p 2025-02-24 185123.png\", \"image\"]}, {\"id\": 133, \"type\": \"Florence2Run\", \"pos\": [-2171.5830078125, 1037.89208984375], \"size\": [400, 352], \"flags\": {}, \"order\": 17, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 192}, {\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"link\": 193}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1}, {\"name\": \"caption\", \"type\": \"STRING\", \"links\": [194], \"slot_index\": 2}, {\"name\": \"data\", \"type\": \"JSON\", \"links\": null, \"slot_index\": 3}], \"properties\": {\"cnr_id\": \"comfyui-florence2\", \"ver\": \"1.0.3\", \"Node name for S&R\": \"Florence2Run\"}, \"widgets_values\": [\"\", \"more_detailed_caption\", false, false, 2048, 4, false, \"\", 475282495362953, \"increment\"]}, {\"id\": 136, \"type\": \"iToolsPromptStylerExtra\", \"pos\": [-1403.97119140625, 911.7665405273438], \"size\": [300, 420], \"flags\": {}, \"order\": 24, \"mode\": 2, \"inputs\": [{\"name\": \"text_positive\", \"type\": \"STRING\", \"widget\": {\"name\": \"text_positive\"}, \"link\": 195}], \"outputs\": [{\"name\": \"positive_prompt\", \"type\": \"STRING\", \"links\": [196], \"slot_index\": 0}, {\"name\": \"negative_prompt\", \"type\": \"STRING\", \"links\": [197], \"slot_index\": 1}, {\"name\": \"used_templates\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"aux_id\": \"fecsaba/ComfyUI-iTools\", \"ver\": \"0.4.9\", \"Node name for S&R\": \"iToolsPromptStylerExtra\", \"cnr_id\": \"comfyui-itools\"}, \"widgets_values\": [\"\", \"ugly, watermark\", \"Drawing.yaml\", \"none\", \"Art.yaml\", \"none\", \"artist.yaml\", \"none\", \"mood.yaml\", \"none\", null], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 137, \"type\": \"easy showAnything\", \"pos\": [-1753.4393310546875, 980.1578979492188], \"size\": [282.40643310546875, 210.21043395996094], \"flags\": {}, \"order\": 21, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 194}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [195], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A close-up of a person wearing a black t-shirt with a graphic design on the front. The design features a white cat with striking green eyes peeking out from behind a torn piece of paper. The cat's paws are visible, and it appears to be in a playful pose. The person wears a gold necklace and a silver watch on their wrist. The background is plain white, highlighting the cat and the person's clothing.\"]}, {\"id\": 147, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": [-589.7310180664062, 914.842041015625], \"size\": [226.8000030517578, 106], \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"yellow\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"always one\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 110, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": [-85.22692108154297, 2001.6812744140625], \"size\": [340.20001220703125, 190], \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 151}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": 152}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [141, 143, 212], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": [209]}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\", \"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 105, \"type\": \"RandomNoise\", \"pos\": [295.4716796875, 1986.357666015625], \"size\": [315, 82], \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [146]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [257208041668693, \"randomize\"]}, {\"id\": 117, \"type\": \"SaveImageWithMetaData\", \"pos\": [2359.031494140625, 1971.2152099609375], \"size\": [315, 482], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 169}, {\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": 167}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"SaveImageWithMetaData\"}, \"widgets_values\": [\"ComfyUI\", \"Farthest\", 0, \"png\", true, 100, false, true, false]}, {\"id\": 108, \"type\": \"SamplerCustomAdvanced\", \"pos\": [790.0797729492188, 1993.872802734375], \"size\": [355.20001220703125, 106], \"flags\": {\"collapsed\": false}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 146}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 147}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 148}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 149}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 150}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [137], \"slot_index\": 0}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 104, \"type\": \"BasicScheduler\", \"pos\": [287.3750915527344, 2133.152099609375], \"size\": [315, 106], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 143}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [149], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 0.9500000000000001]}, {\"id\": 151, \"type\": \"Reroute (rgthree)\", \"pos\": [2123.21923828125, 1769.036376953125], \"size\": [40, 30], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": null, \"has_old_label\": true}], \"outputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 4, \"links\": [238], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 158, \"type\": \"Context Big (rgthree)\", \"pos\": [2841.6455078125, 1846.7999267578125], \"size\": [317.4000244140625, 466], \"flags\": {}, \"order\": 18, \"mode\": 4, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 238}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": [240], \"slot_index\": 7}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [239], \"slot_index\": 19}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 141, \"type\": \"Context Switch Big (rgthree)\", \"pos\": [-351.7754211425781, 2173.8974609375], \"size\": [235.1999969482422, 466], \"flags\": {\"collapsed\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"ctx_01\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 198}, {\"name\": \"ctx_02\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 206}, {\"name\": \"ctx_03\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_04\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_05\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [199, 224], \"slot_index\": 17}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [200]}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 149, \"type\": \"Context Big (rgthree)\", \"pos\": [1042.167724609375, 2166.87744140625], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 212}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": 215}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": 213}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": 214}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 211}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 224}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [216], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 150, \"type\": \"Reroute (rgthree)\", \"pos\": [1440.7125244140625, 1946.150146484375], \"size\": [40, 30], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 216, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [217], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 155, \"type\": \"SaveImageWithMetaData\", \"pos\": [3221.05810546875, 1994.283447265625], \"size\": [315, 482], \"flags\": {}, \"order\": 25, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 240}, {\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": 235}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"SaveImageWithMetaData\"}, \"widgets_values\": [\"Not_upscaled\", \"Farthest\", 0, \"png\", true, 100, false, true, false]}, {\"id\": 156, \"type\": \"CreateExtraMetaData\", \"pos\": [2827.42333984375, 2522.215087890625], \"size\": [367.79998779296875, 226], \"flags\": {}, \"order\": 22, \"mode\": 4, \"inputs\": [{\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": null}, {\"name\": \"value1\", \"type\": \"STRING\", \"widget\": {\"name\": \"value1\"}, \"link\": 239}], \"outputs\": [{\"name\": \"EXTRA_METADATA\", \"type\": \"EXTRA_METADATA\", \"links\": [235], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"CreateExtraMetaData\"}, \"widgets_values\": [\"Pos\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]}, {\"id\": 107, \"type\": \"easy positive\", \"pos\": [-1712.91796875, 1949.358154296875], \"size\": [400, 200], \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"links\": [135], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy positive\"}, \"widgets_values\": [\"A white cat with striking bright green eyes peeking out from behind a torn piece of paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain white background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[135, 107, 0, 97, 0, \"STRING\"], [136, 96, 0, 97, 1, \"STRING\"], [137, 108, 0, 99, 0, \"LATENT\"], [138, 98, 0, 99, 1, \"VAE\"], [139, 95, 0, 100, 0, \"CLIP\"], [141, 110, 0, 103, 0, \"MODEL\"], [142, 106, 0, 103, 1, \"CONDITIONING\"], [143, 110, 0, 104, 0, \"MODEL\"], [146, 105, 0, 108, 0, \"NOISE\"], [147, 103, 0, 108, 1, \"GUIDER\"], [148, 102, 0, 108, 2, \"SAMPLER\"], [149, 104, 0, 108, 3, \"SIGMAS\"], [150, 109, 0, 108, 4, \"LATENT\"], [151, 111, 0, 110, 0, \"MODEL\"], [152, 95, 0, 110, 1, \"CLIP\"], [153, 99, 0, 112, 0, \"IMAGE\"], [159, 113, 0, 77, 5, \"UPSCALE_MODEL\"], [163, 116, 0, 109, 0, \"INT\"], [164, 116, 1, 109, 1, \"INT\"], [167, 118, 0, 117, 1, \"EXTRA_METADATA\"], [169, 77, 0, 117, 0, \"IMAGE\"], [170, 118, 0, 119, 0, \"*\"], [176, 101, 0, 121, 19, \"STRING\"], [177, 97, 0, 121, 17, \"STRING\"], [192, 138, 0, 133, 0, \"IMAGE\"], [193, 134, 0, 133, 1, \"FL2MODEL\"], [194, 133, 2, 137, 0, \"*\"], [195, 137, 0, 136, 0, \"STRING\"], [196, 136, 0, 139, 0, \"*\"], [197, 136, 1, 135, 0, \"*\"], [198, 124, 0, 141, 0, \"RGTHREE_CONTEXT\"], [199, 141, 17, 106, 1, \"STRING\"], [200, 141, 19, 100, 1, \"STRING\"], [202, 139, 0, 143, 17, \"STRING\"], [203, 135, 0, 143, 19, \"STRING\"], [204, 143, 0, 144, 0, \"*\"], [205, 144, 0, 145, 0, \"*\"], [206, 145, 0, 141, 1, \"RGTHREE_CONTEXT\"], [209, 110, 1, 106, 0, \"CLIP\"], [210, 121, 0, 124, 0, \"*\"], [211, 99, 0, 149, 7, \"IMAGE\"], [212, 110, 0, 149, 1, \"MODEL\"], [213, 106, 0, 149, 4, \"CONDITIONING\"], [214, 100, 0, 149, 5, \"CONDITIONING\"], [215, 98, 0, 149, 3, \"VAE\"], [216, 149, 0, 150, 0, \"*\"], [217, 150, 0, 152, 0, \"RGTHREE_CONTEXT\"], [219, 152, 7, 77, 0, \"IMAGE\"], [220, 152, 1, 77, 1, \"MODEL\"], [221, 152, 4, 77, 2, \"CONDITIONING\"], [222, 152, 5, 77, 3, \"CONDITIONING\"], [223, 152, 3, 77, 4, \"VAE\"], [224, 141, 17, 149, 17, \"STRING\"], [225, 152, 17, 118, 1, \"STRING\"], [231, 77, 0, 153, 0, \"IMAGE\"], [232, 99, 0, 153, 1, \"IMAGE\"], [235, 156, 0, 155, 1, \"EXTRA_METADATA\"], [238, 151, 0, 158, 0, \"RGTHREE_CONTEXT\"], [239, 158, 19, 156, 1, \"STRING\"], [240, 158, 7, 155, 0, \"IMAGE\"]], \"groups\": [{\"id\": 3, \"title\": \"Prompts\", \"bounding\": [-1726.4249267578125, 1875.7581787109375, 837.19189453125, 402.0699768066406], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"id\": 4, \"title\": \"IMG2TXT\", \"bounding\": [-2606.678955078125, 845.7027587890625, 1959.609619140625, 618.3355102539062], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"id\": 5, \"title\": \"GGUF\", \"bounding\": [-361.7754211425781, 1912.7576904296875, 1722.501953125, 773.0628662109375], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"id\": 6, \"title\": \"Upscale\", \"bounding\": [1519.2525634765625, 1877.4429931640625, 1185.050537109375, 1061.74267578125], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.116781577942482, \"offset\": {\"0\": 1998.8223876953125, \"1\": -1759.6571044921875}}, \"node_versions\": {\"ComfyUI-Easy-Use\": \"aadbb0b38945eba3e15be6099a7f4e5c0327c175\", \"ComfyUI-GGUF\": \"5875c52f59baca3a9372d68c43a3775e21846fe0\", \"ComfyUI-Crystools\": \"72e2e9af4a6b9a58ca5d753cacff37ba1ff9bfa8\", \"comfy-core\": \"0.3.14\", \"rgthree-comfy\": \"31b784bac495160436a8cd91bf1a856cf01a738e\", \"ComfyUI-Florence2\": \"90b012e922f8bb0482bcd2ae24cdc191ec12a11f\", \"ComfyUI-iTools\": \"c1847d1aa6115bf52fec2440fa5a235235d1477f\", \"ControlAltAI-Nodes\": \"404b22d09283b2ece48da6c4e024d4d6beaecb07\", \"ComfyUI_UltimateSDUpscale\": \"ff3fdfeee03de46d4462211cffd165d27155e858\", \"ComfyUI-SaveImageWithMetaData\": \"dc9990fc20c1a8c4041cb090f07b1ffe5cb21cf2\"}, \"groupNodes\": {}}, \"version\": 0.4, \"seed_widgets\": {\"77\": 1, \"105\": 0, \"133\": 8}, \"widget_idx_map\": {\"77\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"102\": {\"sampler_name\": 0}, \"104\": {\"scheduler\": 0}, \"105\": {\"noise_seed\": 0}, \"133\": {\"seed\": 8}}}\n",
            "\n",
            "\n",
            "Metaadatok a következő fájlhoz: ComfyUI_00013_.png\n",
            "--------------------------------------------------\n",
            "**parameters**:\n",
            "A white cat with striking bright green eyes peeking out from behind a torn piece of black paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain black background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.,perfection style, Cinematic Photography style,\n",
            "Negative prompt: \n",
            "Steps: 20, Sampler: euler_sgm_uniform, Seed: 871123092213814, VAE: ae.safetensors, VAE hash: afc8e28272, Lora_0 Model name: Stock_Footage_Style_XL_F1D.safetensors, Lora_0 Model hash: 29a06a259b, Lora_0 Strength model: 1, Lora_0 Strength clip: 1, Hashes: {\"vae\": \"afc8e28272\", \"lora:Stock_Footage_Style_XL_F1D\": \"29a06a259b\"}, Pos: A white cat with striking bright green eyes peeking out from behind a torn piece of black paper/ highly detailed fur texture/ soft lighting/ playful and curious expression/ visible paws in a playful pose/ realistic and lifelike/ set against a plain black background/ ultra-detailed whiskers and claws/ photorealistic style/ 8k resolution/ art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth./perfection style/ Cinematic Photography style/\n",
            "\n",
            "**prompt**:\n",
            "{\"95\": {\"inputs\": {\"clip_name1\": \"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoaderGGUF\", \"_meta\": {\"title\": \"DualCLIPLoader (GGUF)\"}}, \"96\": {\"inputs\": {\"string\": \"perfection style, Cinematic Photography style,\"}, \"class_type\": \"Primitive string [Crystools]\", \"_meta\": {\"title\": \"Lora trigger\"}}, \"97\": {\"inputs\": {\"prompt1\": [\"107\", 0], \"prompt2\": [\"96\", 0], \"separator\": \",\"}, \"class_type\": \"easy promptConcat\", \"_meta\": {\"title\": \"PromptConcat\"}}, \"98\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\", \"_meta\": {\"title\": \"Load VAE\"}}, \"99\": {\"inputs\": {\"samples\": [\"108\", 0], \"vae\": [\"98\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"100\": {\"inputs\": {\"text\": [\"141\", 19], \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Negative (not used))\"}}, \"101\": {\"inputs\": {\"negative\": \"\"}, \"class_type\": \"easy negative\", \"_meta\": {\"title\": \"Negative\"}}, \"102\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"103\": {\"inputs\": {\"model\": [\"110\", 0], \"conditioning\": [\"106\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"104\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 20, \"denoise\": 1.0, \"model\": [\"110\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"105\": {\"inputs\": {\"noise_seed\": 871123092213814}, \"class_type\": \"RandomNoise\", \"_meta\": {\"title\": \"RandomNoise\"}}, \"106\": {\"inputs\": {\"text\": [\"141\", 17], \"clip\": [\"110\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"107\": {\"inputs\": {\"positive\": \"A white cat with striking bright green eyes peeking out from behind a torn piece of black paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain black background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.\"}, \"class_type\": \"easy positive\", \"_meta\": {\"title\": \"Positive\"}}, \"108\": {\"inputs\": {\"noise\": [\"105\", 0], \"guider\": [\"103\", 0], \"sampler\": [\"102\", 0], \"sigmas\": [\"104\", 0], \"latent_image\": [\"109\", 0]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"109\": {\"inputs\": {\"width\": [\"116\", 0], \"height\": [\"116\", 1], \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\", \"_meta\": {\"title\": \"EmptySD3LatentImage\"}}, \"110\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1}, \"lora_2\": {\"on\": true, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1}, \"lora_3\": {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1}, \"\\u2795 Add Lora\": \"\", \"model\": [\"111\", 0], \"clip\": [\"95\", 0]}, \"class_type\": \"Power Lora Loader (rgthree)\", \"_meta\": {\"title\": \"Power Lora Loader (rgthree)\"}}, \"111\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q4_K_S.gguf\"}, \"class_type\": \"UnetLoaderGGUF\", \"_meta\": {\"title\": \"Unet Loader (GGUF)\"}}, \"112\": {\"inputs\": {\"images\": [\"99\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"113\": {\"inputs\": {\"model_name\": \"ESRGAN_4x.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"116\": {\"inputs\": {\"megapixel\": \"1.0\", \"aspect_ratio\": \"9:16 (Slim Vertical)\", \"custom_ratio\": false, \"custom_aspect_ratio\": \"1:1\"}, \"class_type\": \"FluxResolutionNode\", \"_meta\": {\"title\": \"Flux Resolution Calc\"}}, \"117\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"sampler_selection_method\": \"Farthest\", \"sampler_selection_node_id\": 0, \"file_format\": \"png\", \"lossless_webp\": true, \"quality\": 100, \"save_workflow_json\": false, \"add_counter_to_filename\": true, \"civitai_sampler\": false, \"images\": [\"152\", 7], \"extra_metadata\": [\"118\", 0]}, \"class_type\": \"SaveImageWithMetaData\", \"_meta\": {\"title\": \"Save Image With Metadata\"}}, \"118\": {\"inputs\": {\"key1\": \"Pos\", \"value1\": [\"152\", 17], \"key2\": \"\", \"value2\": \"\", \"key3\": \"\", \"value3\": \"\", \"key4\": \"\", \"value4\": \"\"}, \"class_type\": \"CreateExtraMetaData\", \"_meta\": {\"title\": \"Create Extra MetaData\"}}, \"119\": {\"inputs\": {\"text\": \"{\\\"Pos\\\": \\\"A white cat with striking bright green eyes peeking out from behind a torn piece of black paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain black background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.,perfection style, Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\", \"anything\": [\"118\", 0]}, \"class_type\": \"easy showAnything\", \"_meta\": {\"title\": \"Show Any\"}}, \"121\": {\"inputs\": {\"text_pos_g\": [\"97\", 0], \"text_neg_g\": [\"101\", 0]}, \"class_type\": \"Context Big (rgthree)\", \"_meta\": {\"title\": \"Context Big (rgthree)\"}}, \"141\": {\"inputs\": {\"ctx_01\": [\"121\", 0]}, \"class_type\": \"Context Switch Big (rgthree)\", \"_meta\": {\"title\": \"Context Switch Big (rgthree)\"}}, \"149\": {\"inputs\": {\"model\": [\"110\", 0], \"vae\": [\"98\", 0], \"positive\": [\"106\", 0], \"negative\": [\"100\", 0], \"images\": [\"99\", 0], \"text_pos_g\": [\"141\", 17]}, \"class_type\": \"Context Big (rgthree)\", \"_meta\": {\"title\": \"Context Big (rgthree)\"}}, \"152\": {\"inputs\": {\"ctx_01\": [\"149\", 0]}, \"class_type\": \"Context Merge Big (rgthree)\", \"_meta\": {\"title\": \"Context Merge Big (rgthree)\"}}, \"153\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00029_.png&type=temp&subfolder=&rand=0.9047847854694349\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00030_.png&type=temp&subfolder=&rand=0.47342262349029496\"}]}, \"image_a\": [\"152\", 7], \"image_b\": [\"99\", 0]}, \"class_type\": \"Image Comparer (rgthree)\", \"_meta\": {\"title\": \"Image Comparer (rgthree)\"}}}\n",
            "\n",
            "**workflow**:\n",
            "{\"last_node_id\": 158, \"last_link_id\": 240, \"nodes\": [{\"id\": 116, \"type\": \"FluxResolutionNode\", \"pos\": [-85.54752349853516, 2331.3125], \"size\": [315, 190], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [163], \"slot_index\": 0}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [164], \"slot_index\": 1}, {\"name\": \"resolution\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"preview\", \"type\": \"IMAGE\", \"links\": null}], \"properties\": {\"cnr_id\": \"controlaltai-nodes\", \"ver\": \"404b22d09283b2ece48da6c4e024d4d6beaecb07\", \"Node name for S&R\": \"FluxResolutionNode\"}, \"widgets_values\": [\"1.0\", \"9:16 (Slim Vertical)\", false, \"1:1\"]}, {\"id\": 96, \"type\": \"Primitive string [Crystools]\", \"pos\": [-1716.4249267578125, 2209.827392578125], \"size\": [315, 58], \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"links\": [136]}], \"title\": \"Lora trigger\", \"properties\": {\"cnr_id\": \"comfyui-crystools\", \"ver\": \"72e2e9af4a6b9a58ca5d753cacff37ba1ff9bfa8\", \"Node name for S&R\": \"Primitive string [Crystools]\"}, \"widgets_values\": [\"perfection style, Cinematic Photography style,\"]}, {\"id\": 103, \"type\": \"BasicGuider\", \"pos\": [291.2577209472656, 2283.659423828125], \"size\": [241.79998779296875, 46], \"flags\": {\"collapsed\": false}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 141}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 142}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [147]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 109, \"type\": \"EmptySD3LatentImage\", \"pos\": [302.2720642089844, 2504.952880859375], \"size\": [315, 106], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"widget\": {\"name\": \"width\"}, \"link\": 163}, {\"name\": \"height\", \"type\": \"INT\", \"widget\": {\"name\": \"height\"}, \"link\": 164}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 102, \"type\": \"KSamplerSelect\", \"pos\": [295.0891418457031, 2391.32861328125], \"size\": [315, 58], \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [148]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 95, \"type\": \"DualCLIPLoaderGGUF\", \"pos\": [-333.3307800292969, 2075.8251953125], \"size\": [315, 106], \"flags\": {\"collapsed\": true}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [139, 152], \"slot_index\": 0}], \"properties\": {\"aux_id\": \"city96/ComfyUI-GGUF\", \"ver\": \"e024aab10d0444dcaf88d7abec3ab98a62b66043\", \"Node name for S&R\": \"DualCLIPLoaderGGUF\"}, \"widgets_values\": [\"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 111, \"type\": \"UnetLoaderGGUF\", \"pos\": [-322.04339599609375, 2136.907958984375], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"aux_id\": \"city96/ComfyUI-GGUF\", \"ver\": \"e024aab10d0444dcaf88d7abec3ab98a62b66043\", \"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q4_K_S.gguf\"]}, {\"id\": 139, \"type\": \"easy showAnything\", \"pos\": [-975.3072509765625, 925.1323852539062], \"size\": [318.237548828125, 233.9617919921875], \"flags\": {}, \"order\": 27, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 196}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [202], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A close-up of a person wearing a black t-shirt with a graphic design on the front. The design features a white cat with striking green eyes peeking out from behind a torn piece of paper. The cat's paws are visible, and it appears to be in a playful pose. The person wears a gold necklace and a silver watch on their wrist. The background is plain white, highlighting the cat and the person's clothing..\"]}, {\"id\": 135, \"type\": \"easy showAnything\", \"pos\": [-943.4004516601562, 1222.51806640625], \"size\": [262.2000427246094, 231.5201416015625], \"flags\": {}, \"order\": 28, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 197}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [203], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"ugly, watermark, ugly, watermark,\"]}, {\"id\": 144, \"type\": \"Reroute (rgthree)\", \"pos\": [-461.2772216796875, 1088.3099365234375], \"size\": [40, 30], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 204, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [205], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30]}}, {\"id\": 143, \"type\": \"Context Big (rgthree)\", \"pos\": [-1128.98779296875, 1400.7568359375], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 29, \"mode\": 2, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 202}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 203}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [204], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 134, \"type\": \"DownloadAndLoadFlorence2Model\", \"pos\": [-2585.100830078125, 1315.996826171875], \"size\": [365.4000244140625, 106], \"flags\": {}, \"order\": 5, \"mode\": 2, \"inputs\": [{\"name\": \"lora\", \"type\": \"PEFTLORA\", \"shape\": 7, \"link\": null}], \"outputs\": [{\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"links\": [193], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-florence2\", \"ver\": \"1.0.3\", \"Node name for S&R\": \"DownloadAndLoadFlorence2Model\"}, \"widgets_values\": [\"thwri/CogFlorence-2.2-Large\", \"fp16\", \"sdpa\"]}, {\"id\": 124, \"type\": \"Reroute (rgthree)\", \"pos\": [-536.951171875, 1944.7838134765625], \"size\": [40, 30], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 210, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [198], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 101, \"type\": \"easy negative\", \"pos\": [-1296.494873046875, 1946.167236328125], \"size\": [400, 200], \"flags\": {\"collapsed\": false}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"negative\", \"type\": \"STRING\", \"links\": [176], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy negative\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 121, \"type\": \"Context Big (rgthree)\", \"pos\": [-1206.7908935546875, 2194.957763671875], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 177}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 176}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [210], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 97, \"type\": \"easy promptConcat\", \"pos\": [-1203.9688720703125, 2245.002197265625], \"size\": [315, 106], \"flags\": {\"collapsed\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt1\"}, \"link\": 135}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt2\"}, \"link\": 136}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [177], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 106, \"type\": \"CLIPTextEncode\", \"pos\": [-24.871721267700195, 2225.4462890625], \"size\": [422.84503173828125, 164.31304931640625], \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 209}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 199}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [142, 213], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"closeup portrait of a sci-fi warrior robot, rusty metal, mech, cinematic, red eyes, dark interior background, movie scene, sharp, rim light, epic, golden hour\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 100, \"type\": \"CLIPTextEncode\", \"pos\": [-25.847551345825195, 2271.742919921875], \"size\": [425.27801513671875, 180.6060791015625], \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 139}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 200}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [214], \"slot_index\": 0}], \"title\": \"Negative (not used))\", \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 98, \"type\": \"VAELoader\", \"pos\": [645.3443603515625, 2215.0732421875], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [138, 215], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 145, \"type\": \"Reroute (rgthree)\", \"pos\": [-354.1865539550781, 1744.037109375], \"size\": [40, 30], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 205, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [206], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 118, \"type\": \"CreateExtraMetaData\", \"pos\": [1982.21728515625, 2609.320556640625], \"size\": [367.79998779296875, 226], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": null}, {\"name\": \"value1\", \"type\": \"STRING\", \"widget\": {\"name\": \"value1\"}, \"link\": 225}], \"outputs\": [{\"name\": \"EXTRA_METADATA\", \"type\": \"EXTRA_METADATA\", \"links\": [167, 170], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"CreateExtraMetaData\"}, \"widgets_values\": [\"Pos\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]}, {\"id\": 119, \"type\": \"easy showAnything\", \"pos\": [2408.923583984375, 2572.09814453125], \"size\": [239.81918334960938, 357.0870361328125], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 170}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": null}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [[\"{\\\"Pos\\\": \\\"A white cat with striking bright green eyes peeking out from behind a torn piece of black paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain black background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.,perfection style, Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\"]]}, {\"id\": 152, \"type\": \"Context Merge Big (rgthree)\", \"pos\": [1578.6474609375, 2086.99560546875], \"size\": [226.8000030517578, 466], \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"ctx_01\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 217}, {\"name\": \"ctx_02\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_03\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_04\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_05\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [220], \"slot_index\": 1}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": [223], \"slot_index\": 3}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": [221], \"slot_index\": 4}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": [222], \"slot_index\": 5}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": [219], \"slot_index\": 7}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [225], \"slot_index\": 17}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 42, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": [-114.01629638671875, 868.0133056640625], \"size\": [226.8000030517578, 202], \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}}, {\"id\": 113, \"type\": \"UpscaleModelLoader\", \"pos\": [1529.2525634765625, 1965.1983642578125], \"size\": [315, 58], \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [159], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"ESRGAN_4x.pth\"]}, {\"id\": 99, \"type\": \"VAEDecode\", \"pos\": [686.040283203125, 2142.46142578125], \"size\": [210, 46], \"flags\": {\"collapsed\": false}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 137}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 138}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [153, 211, 232], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 77, \"type\": \"UltimateSDUpscale\", \"pos\": [1918.5362548828125, 1951.04296875], \"size\": [315, 614], \"flags\": {}, \"order\": 42, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 219}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 220}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 221}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 222}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 223}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 159}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [169, 231], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui_ultimatesdupscale\", \"ver\": \"ff3fdfeee03de46d4462211cffd165d27155e858\", \"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [4, 627362334615295, \"increment\", 20, 1, \"euler\", \"normal\", 0.12, \"Linear\", 512, 512, 8, 0, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 153, \"type\": \"Image Comparer (rgthree)\", \"pos\": [846.02734375, 2832.2861328125], \"size\": [663.0813598632812, 731.4021606445312], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 231}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 232}], \"outputs\": [], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\", \"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00029_.png&type=temp&subfolder=&rand=0.9047847854694349\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_bantp_00030_.png&type=temp&subfolder=&rand=0.47342262349029496\"}]]}, {\"id\": 138, \"type\": \"LoadImage\", \"pos\": [-2596.678955078125, 919.302734375], \"size\": [315, 314], \"flags\": {}, \"order\": 10, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [192], \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"K\\u00e9perny\\u0151k\\u00e9p 2025-02-24 185123.png\", \"image\"]}, {\"id\": 133, \"type\": \"Florence2Run\", \"pos\": [-2171.5830078125, 1037.89208984375], \"size\": [400, 352], \"flags\": {}, \"order\": 17, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 192}, {\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"link\": 193}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1}, {\"name\": \"caption\", \"type\": \"STRING\", \"links\": [194], \"slot_index\": 2}, {\"name\": \"data\", \"type\": \"JSON\", \"links\": null, \"slot_index\": 3}], \"properties\": {\"cnr_id\": \"comfyui-florence2\", \"ver\": \"1.0.3\", \"Node name for S&R\": \"Florence2Run\"}, \"widgets_values\": [\"\", \"more_detailed_caption\", false, false, 2048, 4, false, \"\", 475282495362961, \"increment\"]}, {\"id\": 136, \"type\": \"iToolsPromptStylerExtra\", \"pos\": [-1403.97119140625, 911.7665405273438], \"size\": [300, 420], \"flags\": {}, \"order\": 24, \"mode\": 2, \"inputs\": [{\"name\": \"text_positive\", \"type\": \"STRING\", \"widget\": {\"name\": \"text_positive\"}, \"link\": 195}], \"outputs\": [{\"name\": \"positive_prompt\", \"type\": \"STRING\", \"links\": [196], \"slot_index\": 0}, {\"name\": \"negative_prompt\", \"type\": \"STRING\", \"links\": [197], \"slot_index\": 1}, {\"name\": \"used_templates\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"aux_id\": \"fecsaba/ComfyUI-iTools\", \"ver\": \"0.4.9\", \"Node name for S&R\": \"iToolsPromptStylerExtra\", \"cnr_id\": \"comfyui-itools\"}, \"widgets_values\": [\"\", \"ugly, watermark\", \"Drawing.yaml\", \"none\", \"Art.yaml\", \"none\", \"artist.yaml\", \"none\", \"mood.yaml\", \"none\", null], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 137, \"type\": \"easy showAnything\", \"pos\": [-1753.4393310546875, 980.1578979492188], \"size\": [282.40643310546875, 210.21043395996094], \"flags\": {}, \"order\": 21, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 194}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [195], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A close-up of a person wearing a black t-shirt with a graphic design on the front. The design features a white cat with striking green eyes peeking out from behind a torn piece of paper. The cat's paws are visible, and it appears to be in a playful pose. The person wears a gold necklace and a silver watch on their wrist. The background is plain white, highlighting the cat and the person's clothing.\"]}, {\"id\": 147, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": [-589.7310180664062, 914.842041015625], \"size\": [226.8000030517578, 106], \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"yellow\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"always one\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 110, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": [-85.22692108154297, 2001.6812744140625], \"size\": [340.20001220703125, 190], \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 151}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": 152}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [141, 143, 212], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": [209]}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\", \"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": false, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 117, \"type\": \"SaveImageWithMetaData\", \"pos\": [2359.031494140625, 1971.2152099609375], \"size\": [315, 482], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 169}, {\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": 167}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"SaveImageWithMetaData\"}, \"widgets_values\": [\"ComfyUI\", \"Farthest\", 0, \"png\", true, 100, false, true, false]}, {\"id\": 108, \"type\": \"SamplerCustomAdvanced\", \"pos\": [790.0797729492188, 1993.872802734375], \"size\": [355.20001220703125, 106], \"flags\": {\"collapsed\": false}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 146}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 147}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 148}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 149}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 150}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [137], \"slot_index\": 0}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 151, \"type\": \"Reroute (rgthree)\", \"pos\": [2123.21923828125, 1769.036376953125], \"size\": [40, 30], \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": null, \"has_old_label\": true}], \"outputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 4, \"links\": [238], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 158, \"type\": \"Context Big (rgthree)\", \"pos\": [2841.6455078125, 1846.7999267578125], \"size\": [317.4000244140625, 466], \"flags\": {}, \"order\": 18, \"mode\": 4, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 238}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": [240], \"slot_index\": 7}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [239], \"slot_index\": 19}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 141, \"type\": \"Context Switch Big (rgthree)\", \"pos\": [-351.7754211425781, 2173.8974609375], \"size\": [235.1999969482422, 466], \"flags\": {\"collapsed\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"ctx_01\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 198}, {\"name\": \"ctx_02\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 206}, {\"name\": \"ctx_03\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_04\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_05\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [199, 224], \"slot_index\": 17}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [200]}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 149, \"type\": \"Context Big (rgthree)\", \"pos\": [1042.167724609375, 2166.87744140625], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 212}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": 215}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": 213}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": 214}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 211}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 224}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [216], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 150, \"type\": \"Reroute (rgthree)\", \"pos\": [1440.7125244140625, 1946.150146484375], \"size\": [40, 30], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 216, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [217], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 155, \"type\": \"SaveImageWithMetaData\", \"pos\": [3221.05810546875, 1994.283447265625], \"size\": [315, 482], \"flags\": {}, \"order\": 25, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 240}, {\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": 235}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"SaveImageWithMetaData\"}, \"widgets_values\": [\"Not_upscaled\", \"Farthest\", 0, \"png\", true, 100, false, true, false]}, {\"id\": 156, \"type\": \"CreateExtraMetaData\", \"pos\": [2827.42333984375, 2522.215087890625], \"size\": [367.79998779296875, 226], \"flags\": {}, \"order\": 22, \"mode\": 4, \"inputs\": [{\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": null}, {\"name\": \"value1\", \"type\": \"STRING\", \"widget\": {\"name\": \"value1\"}, \"link\": 239}], \"outputs\": [{\"name\": \"EXTRA_METADATA\", \"type\": \"EXTRA_METADATA\", \"links\": [235], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"CreateExtraMetaData\"}, \"widgets_values\": [\"Pos\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]}, {\"id\": 105, \"type\": \"RandomNoise\", \"pos\": [295.4716796875, 1986.357666015625], \"size\": [315, 82], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [146]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [871123092213814, \"fixed\"]}, {\"id\": 112, \"type\": \"PreviewImage\", \"pos\": [707.58642578125, 2250.92431640625], \"size\": [210, 246], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 153}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 107, \"type\": \"easy positive\", \"pos\": [-1712.91796875, 1949.358154296875], \"size\": [400, 200], \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"links\": [135], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy positive\"}, \"widgets_values\": [\"A white cat with striking bright green eyes peeking out from behind a torn piece of black paper, highly detailed fur texture, soft lighting, playful and curious expression, visible paws in a playful pose, realistic and lifelike, set against a plain black background, ultra-detailed whiskers and claws, photorealistic style, 8k resolution, art by Albert Hirai and David Revoy. Soft bokeh effect around the edges to enhance depth.\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 104, \"type\": \"BasicScheduler\", \"pos\": [287.3750915527344, 2133.152099609375], \"size\": [315, 106], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 143}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [149], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 20, 1]}], \"links\": [[135, 107, 0, 97, 0, \"STRING\"], [136, 96, 0, 97, 1, \"STRING\"], [137, 108, 0, 99, 0, \"LATENT\"], [138, 98, 0, 99, 1, \"VAE\"], [139, 95, 0, 100, 0, \"CLIP\"], [141, 110, 0, 103, 0, \"MODEL\"], [142, 106, 0, 103, 1, \"CONDITIONING\"], [143, 110, 0, 104, 0, \"MODEL\"], [146, 105, 0, 108, 0, \"NOISE\"], [147, 103, 0, 108, 1, \"GUIDER\"], [148, 102, 0, 108, 2, \"SAMPLER\"], [149, 104, 0, 108, 3, \"SIGMAS\"], [150, 109, 0, 108, 4, \"LATENT\"], [151, 111, 0, 110, 0, \"MODEL\"], [152, 95, 0, 110, 1, \"CLIP\"], [153, 99, 0, 112, 0, \"IMAGE\"], [159, 113, 0, 77, 5, \"UPSCALE_MODEL\"], [163, 116, 0, 109, 0, \"INT\"], [164, 116, 1, 109, 1, \"INT\"], [167, 118, 0, 117, 1, \"EXTRA_METADATA\"], [169, 77, 0, 117, 0, \"IMAGE\"], [170, 118, 0, 119, 0, \"*\"], [176, 101, 0, 121, 19, \"STRING\"], [177, 97, 0, 121, 17, \"STRING\"], [192, 138, 0, 133, 0, \"IMAGE\"], [193, 134, 0, 133, 1, \"FL2MODEL\"], [194, 133, 2, 137, 0, \"*\"], [195, 137, 0, 136, 0, \"STRING\"], [196, 136, 0, 139, 0, \"*\"], [197, 136, 1, 135, 0, \"*\"], [198, 124, 0, 141, 0, \"RGTHREE_CONTEXT\"], [199, 141, 17, 106, 1, \"STRING\"], [200, 141, 19, 100, 1, \"STRING\"], [202, 139, 0, 143, 17, \"STRING\"], [203, 135, 0, 143, 19, \"STRING\"], [204, 143, 0, 144, 0, \"*\"], [205, 144, 0, 145, 0, \"*\"], [206, 145, 0, 141, 1, \"RGTHREE_CONTEXT\"], [209, 110, 1, 106, 0, \"CLIP\"], [210, 121, 0, 124, 0, \"*\"], [211, 99, 0, 149, 7, \"IMAGE\"], [212, 110, 0, 149, 1, \"MODEL\"], [213, 106, 0, 149, 4, \"CONDITIONING\"], [214, 100, 0, 149, 5, \"CONDITIONING\"], [215, 98, 0, 149, 3, \"VAE\"], [216, 149, 0, 150, 0, \"*\"], [217, 150, 0, 152, 0, \"RGTHREE_CONTEXT\"], [219, 152, 7, 77, 0, \"IMAGE\"], [220, 152, 1, 77, 1, \"MODEL\"], [221, 152, 4, 77, 2, \"CONDITIONING\"], [222, 152, 5, 77, 3, \"CONDITIONING\"], [223, 152, 3, 77, 4, \"VAE\"], [224, 141, 17, 149, 17, \"STRING\"], [225, 152, 17, 118, 1, \"STRING\"], [231, 77, 0, 153, 0, \"IMAGE\"], [232, 99, 0, 153, 1, \"IMAGE\"], [235, 156, 0, 155, 1, \"EXTRA_METADATA\"], [238, 151, 0, 158, 0, \"RGTHREE_CONTEXT\"], [239, 158, 19, 156, 1, \"STRING\"], [240, 158, 7, 155, 0, \"IMAGE\"]], \"groups\": [{\"id\": 3, \"title\": \"Prompts\", \"bounding\": [-1726.4249267578125, 1875.7581787109375, 837.19189453125, 402.0699768066406], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"id\": 4, \"title\": \"IMG2TXT\", \"bounding\": [-2606.678955078125, 845.7027587890625, 1959.609619140625, 618.3355102539062], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"id\": 5, \"title\": \"GGUF\", \"bounding\": [-361.7754211425781, 1912.7576904296875, 1722.501953125, 773.0628662109375], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"id\": 6, \"title\": \"Upscale\", \"bounding\": [1519.2525634765625, 1877.4429931640625, 1185.050537109375, 1061.74267578125], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 2.17629135790151, \"offset\": {\"0\": -340.2945556640625, \"1\": -2187.516845703125}}, \"node_versions\": {\"ComfyUI-Easy-Use\": \"aadbb0b38945eba3e15be6099a7f4e5c0327c175\", \"ComfyUI-GGUF\": \"5875c52f59baca3a9372d68c43a3775e21846fe0\", \"ComfyUI-Crystools\": \"72e2e9af4a6b9a58ca5d753cacff37ba1ff9bfa8\", \"comfy-core\": \"0.3.14\", \"rgthree-comfy\": \"31b784bac495160436a8cd91bf1a856cf01a738e\", \"ComfyUI-Florence2\": \"90b012e922f8bb0482bcd2ae24cdc191ec12a11f\", \"ComfyUI-iTools\": \"c1847d1aa6115bf52fec2440fa5a235235d1477f\", \"ControlAltAI-Nodes\": \"404b22d09283b2ece48da6c4e024d4d6beaecb07\", \"ComfyUI_UltimateSDUpscale\": \"ff3fdfeee03de46d4462211cffd165d27155e858\", \"ComfyUI-SaveImageWithMetaData\": \"dc9990fc20c1a8c4041cb090f07b1ffe5cb21cf2\"}, \"groupNodes\": {}}, \"version\": 0.4, \"seed_widgets\": {\"77\": 1, \"105\": 0, \"133\": 8}, \"widget_idx_map\": {\"77\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"102\": {\"sampler_name\": 0}, \"104\": {\"scheduler\": 0}, \"105\": {\"noise_seed\": 0}, \"133\": {\"seed\": 8}}}\n",
            "\n",
            "\n",
            "Metaadatok a következő fájlhoz: ComfyUI_00006_ (1).png\n",
            "--------------------------------------------------\n",
            "**parameters**:\n",
            "(Ultra-detailed DSLR photo:1.3), (professional pet grooming salon interior), (Golden Retriever with wet fluffy fur, water droplets, 8k fur texture), (Calico cat on marble table, natural sunlight), (stainless steel grooming tools, ceramic shampoo bottles, microfiber towels), soft pastel colors (mint green walls, blush pink accents), (cinematic depth of field, Fujifilm X-T4, f/2.8), photorealistic texture,perfection style, Cinematic Photography style,\n",
            "Negative prompt: \n",
            "Steps: 20, Sampler: euler_beta, Seed: 871123092213814, VAE: ae.safetensors, VAE hash: afc8e28272, Lora_0 Model name: Detailed_Perfection_style.safetensors, Lora_0 Model hash: 9f216fecab, Lora_0 Strength model: 1, Lora_0 Strength clip: 1, Hashes: {\"vae\": \"afc8e28272\", \"lora:Detailed_Perfection_style\": \"9f216fecab\"}, Pos: (Ultra-detailed DSLR photo:1.3)/ (professional pet grooming salon interior)/ (Golden Retriever with wet fluffy fur/ water droplets/ 8k fur texture)/ (Calico cat on marble table/ natural sunlight)/ (stainless steel grooming tools/ ceramic shampoo bottles/ microfiber towels)/ soft pastel colors (mint green walls/ blush pink accents)/ (cinematic depth of field/ Fujifilm X-T4/ f/2.8)/ photorealistic texture/perfection style/ Cinematic Photography style/\n",
            "\n",
            "**prompt**:\n",
            "{\"95\": {\"inputs\": {\"clip_name1\": \"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoaderGGUF\", \"_meta\": {\"title\": \"DualCLIPLoader (GGUF)\"}}, \"96\": {\"inputs\": {\"string\": \"perfection style, Cinematic Photography style,\"}, \"class_type\": \"Primitive string [Crystools]\", \"_meta\": {\"title\": \"Lora trigger\"}}, \"97\": {\"inputs\": {\"prompt1\": [\"107\", 0], \"prompt2\": [\"96\", 0], \"separator\": \",\"}, \"class_type\": \"easy promptConcat\", \"_meta\": {\"title\": \"PromptConcat\"}}, \"98\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\", \"_meta\": {\"title\": \"Load VAE\"}}, \"99\": {\"inputs\": {\"samples\": [\"108\", 0], \"vae\": [\"98\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"100\": {\"inputs\": {\"text\": [\"141\", 19], \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Negative (not used))\"}}, \"101\": {\"inputs\": {\"negative\": \"\"}, \"class_type\": \"easy negative\", \"_meta\": {\"title\": \"Negative\"}}, \"102\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"103\": {\"inputs\": {\"model\": [\"110\", 0], \"conditioning\": [\"106\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"104\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 20, \"denoise\": 0.9, \"model\": [\"110\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"105\": {\"inputs\": {\"noise_seed\": 871123092213814}, \"class_type\": \"RandomNoise\", \"_meta\": {\"title\": \"RandomNoise\"}}, \"106\": {\"inputs\": {\"text\": [\"141\", 17], \"clip\": [\"110\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"107\": {\"inputs\": {\"positive\": \"(Ultra-detailed DSLR photo:1.3), (professional pet grooming salon interior), (Golden Retriever with wet fluffy fur, water droplets, 8k fur texture), (Calico cat on marble table, natural sunlight), (stainless steel grooming tools, ceramic shampoo bottles, microfiber towels), soft pastel colors (mint green walls, blush pink accents), (cinematic depth of field, Fujifilm X-T4, f/2.8), photorealistic texture\"}, \"class_type\": \"easy positive\", \"_meta\": {\"title\": \"Positive\"}}, \"108\": {\"inputs\": {\"noise\": [\"105\", 0], \"guider\": [\"103\", 0], \"sampler\": [\"102\", 0], \"sigmas\": [\"104\", 0], \"latent_image\": [\"109\", 0]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"109\": {\"inputs\": {\"width\": [\"116\", 0], \"height\": [\"116\", 1], \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\", \"_meta\": {\"title\": \"EmptySD3LatentImage\"}}, \"110\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": true, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1}, \"lora_2\": {\"on\": false, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1}, \"lora_3\": {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1}, \"\\u2795 Add Lora\": \"\", \"model\": [\"111\", 0], \"clip\": [\"95\", 0]}, \"class_type\": \"Power Lora Loader (rgthree)\", \"_meta\": {\"title\": \"Power Lora Loader (rgthree)\"}}, \"111\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q4_K_S.gguf\"}, \"class_type\": \"UnetLoaderGGUF\", \"_meta\": {\"title\": \"Unet Loader (GGUF)\"}}, \"112\": {\"inputs\": {\"images\": [\"99\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"113\": {\"inputs\": {\"model_name\": \"ESRGAN_4x.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"116\": {\"inputs\": {\"megapixel\": \"1.0\", \"aspect_ratio\": \"5:7 (Balanced Portrait)\", \"custom_ratio\": false, \"custom_aspect_ratio\": \"1:1.4\"}, \"class_type\": \"FluxResolutionNode\", \"_meta\": {\"title\": \"Flux Resolution Calc\"}}, \"117\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"sampler_selection_method\": \"Farthest\", \"sampler_selection_node_id\": 0, \"file_format\": \"png\", \"lossless_webp\": false, \"quality\": 100, \"save_workflow_json\": false, \"add_counter_to_filename\": true, \"civitai_sampler\": false, \"images\": [\"152\", 7], \"extra_metadata\": [\"118\", 0]}, \"class_type\": \"SaveImageWithMetaData\", \"_meta\": {\"title\": \"Save Image With Metadata\"}}, \"118\": {\"inputs\": {\"key1\": \"Pos\", \"value1\": [\"152\", 17], \"key2\": \"\", \"value2\": \"\", \"key3\": \"\", \"value3\": \"\", \"key4\": \"\", \"value4\": \"\"}, \"class_type\": \"CreateExtraMetaData\", \"_meta\": {\"title\": \"Create Extra MetaData\"}}, \"119\": {\"inputs\": {\"text\": \"{\\\"Pos\\\": \\\"(Ultra-detailed poster design:1.3), (professional pet grooming salon:1.2), (happy fluffy Golden Retriever being brushed), (curious Calico cat with sparkling clean fur), (gentle grooming tools: shampoo bottles, pink brushes, silver scissors), soft pastel colors (mint green, baby blue, blush pink, creamy white), (floating soap bubbles and paw prints in background:1.1), (stylized water splash effects around pets), (modern cartoonish illustration style:1.2) with semi-realistic details, (warm lighting), (small paw + water droplet logo on top corner), (clean typography layout: \\\\\\\"Pampering Pets with Love & Care!\\\\\\\" in bold rounded font), (services listed in pastel-colored bubbles: Bathing, Haircuts, Nail Trimming), (20% discount sticker effect on bottom), (depth of field), trending on ArtStation, Pixar-inspired pastel shading,perfection style, Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\", \"anything\": [\"118\", 0]}, \"class_type\": \"easy showAnything\", \"_meta\": {\"title\": \"Show Any\"}}, \"121\": {\"inputs\": {\"text_pos_g\": [\"97\", 0], \"text_neg_g\": [\"101\", 0]}, \"class_type\": \"Context Big (rgthree)\", \"_meta\": {\"title\": \"Context Big (rgthree)\"}}, \"141\": {\"inputs\": {\"ctx_01\": [\"121\", 0]}, \"class_type\": \"Context Switch Big (rgthree)\", \"_meta\": {\"title\": \"Context Switch Big (rgthree)\"}}, \"149\": {\"inputs\": {\"model\": [\"110\", 0], \"vae\": [\"98\", 0], \"positive\": [\"106\", 0], \"negative\": [\"100\", 0], \"images\": [\"99\", 0], \"text_pos_g\": [\"141\", 17]}, \"class_type\": \"Context Big (rgthree)\", \"_meta\": {\"title\": \"Context Big (rgthree)\"}}, \"152\": {\"inputs\": {\"ctx_01\": [\"149\", 0]}, \"class_type\": \"Context Merge Big (rgthree)\", \"_meta\": {\"title\": \"Context Merge Big (rgthree)\"}}, \"153\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_fisro_00009_.png&type=temp&subfolder=&rand=0.9972346913283903\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_fisro_00010_.png&type=temp&subfolder=&rand=0.8225111659462729\"}]}, \"image_a\": [\"152\", 7], \"image_b\": [\"99\", 0]}, \"class_type\": \"Image Comparer (rgthree)\", \"_meta\": {\"title\": \"Image Comparer (rgthree)\"}}}\n",
            "\n",
            "**workflow**:\n",
            "{\"last_node_id\": 158, \"last_link_id\": 240, \"nodes\": [{\"id\": 96, \"type\": \"Primitive string [Crystools]\", \"pos\": [-1716.4249267578125, 2209.827392578125], \"size\": [315, 58], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"links\": [136]}], \"title\": \"Lora trigger\", \"properties\": {\"cnr_id\": \"comfyui-crystools\", \"ver\": \"72e2e9af4a6b9a58ca5d753cacff37ba1ff9bfa8\", \"Node name for S&R\": \"Primitive string [Crystools]\"}, \"widgets_values\": [\"perfection style, Cinematic Photography style,\"]}, {\"id\": 103, \"type\": \"BasicGuider\", \"pos\": [291.2577209472656, 2283.659423828125], \"size\": [241.79998779296875, 46], \"flags\": {\"collapsed\": false}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 141}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 142}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [147]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 109, \"type\": \"EmptySD3LatentImage\", \"pos\": [302.2720642089844, 2504.952880859375], \"size\": [315, 106], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"widget\": {\"name\": \"width\"}, \"link\": 163}, {\"name\": \"height\", \"type\": \"INT\", \"widget\": {\"name\": \"height\"}, \"link\": 164}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 102, \"type\": \"KSamplerSelect\", \"pos\": [295.0891418457031, 2391.32861328125], \"size\": [315, 58], \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [148]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 95, \"type\": \"DualCLIPLoaderGGUF\", \"pos\": [-333.3307800292969, 2075.8251953125], \"size\": [315, 106], \"flags\": {\"collapsed\": true}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [139, 152], \"slot_index\": 0}], \"properties\": {\"aux_id\": \"city96/ComfyUI-GGUF\", \"ver\": \"e024aab10d0444dcaf88d7abec3ab98a62b66043\", \"Node name for S&R\": \"DualCLIPLoaderGGUF\"}, \"widgets_values\": [\"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 111, \"type\": \"UnetLoaderGGUF\", \"pos\": [-322.04339599609375, 2136.907958984375], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"aux_id\": \"city96/ComfyUI-GGUF\", \"ver\": \"e024aab10d0444dcaf88d7abec3ab98a62b66043\", \"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q4_K_S.gguf\"]}, {\"id\": 139, \"type\": \"easy showAnything\", \"pos\": [-975.3072509765625, 925.1323852539062], \"size\": [318.237548828125, 233.9617919921875], \"flags\": {}, \"order\": 27, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 196}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [202], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A close-up of a person wearing a black t-shirt with a graphic design on the front. The design features a white cat with striking green eyes peeking out from behind a torn piece of paper. The cat's paws are visible, and it appears to be in a playful pose. The person wears a gold necklace and a silver watch on their wrist. The background is plain white, highlighting the cat and the person's clothing..\"]}, {\"id\": 135, \"type\": \"easy showAnything\", \"pos\": [-943.4004516601562, 1222.51806640625], \"size\": [262.2000427246094, 231.5201416015625], \"flags\": {}, \"order\": 28, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 197}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [203], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"ugly, watermark, ugly, watermark,\"]}, {\"id\": 144, \"type\": \"Reroute (rgthree)\", \"pos\": [-461.2772216796875, 1088.3099365234375], \"size\": [40, 30], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 204, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [205], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30]}}, {\"id\": 143, \"type\": \"Context Big (rgthree)\", \"pos\": [-1128.98779296875, 1400.7568359375], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 29, \"mode\": 2, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 202}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 203}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [204], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 134, \"type\": \"DownloadAndLoadFlorence2Model\", \"pos\": [-2585.100830078125, 1315.996826171875], \"size\": [365.4000244140625, 106], \"flags\": {}, \"order\": 4, \"mode\": 2, \"inputs\": [{\"name\": \"lora\", \"type\": \"PEFTLORA\", \"shape\": 7, \"link\": null}], \"outputs\": [{\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"links\": [193], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-florence2\", \"ver\": \"1.0.3\", \"Node name for S&R\": \"DownloadAndLoadFlorence2Model\"}, \"widgets_values\": [\"thwri/CogFlorence-2.2-Large\", \"fp16\", \"sdpa\"]}, {\"id\": 124, \"type\": \"Reroute (rgthree)\", \"pos\": [-536.951171875, 1944.7838134765625], \"size\": [40, 30], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 210, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [198], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 121, \"type\": \"Context Big (rgthree)\", \"pos\": [-1206.7908935546875, 2194.957763671875], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 177}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 176}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [210], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 97, \"type\": \"easy promptConcat\", \"pos\": [-1203.9688720703125, 2245.002197265625], \"size\": [315, 106], \"flags\": {\"collapsed\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt1\"}, \"link\": 135}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"shape\": 7, \"widget\": {\"name\": \"prompt2\"}, \"link\": 136}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [177], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 106, \"type\": \"CLIPTextEncode\", \"pos\": [-24.871721267700195, 2225.4462890625], \"size\": [422.84503173828125, 164.31304931640625], \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 209}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 199}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [142, 213], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"closeup portrait of a sci-fi warrior robot, rusty metal, mech, cinematic, red eyes, dark interior background, movie scene, sharp, rim light, epic, golden hour\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 100, \"type\": \"CLIPTextEncode\", \"pos\": [-25.847551345825195, 2271.742919921875], \"size\": [425.27801513671875, 180.6060791015625], \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 139}, {\"name\": \"text\", \"type\": \"STRING\", \"widget\": {\"name\": \"text\"}, \"link\": 200}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [214], \"slot_index\": 0}], \"title\": \"Negative (not used))\", \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 98, \"type\": \"VAELoader\", \"pos\": [645.3443603515625, 2215.0732421875], \"size\": [315, 58], \"flags\": {\"collapsed\": true}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [138, 215], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 145, \"type\": \"Reroute (rgthree)\", \"pos\": [-354.1865539550781, 1744.037109375], \"size\": [40, 30], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 205, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [206], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 118, \"type\": \"CreateExtraMetaData\", \"pos\": [1982.21728515625, 2609.320556640625], \"size\": [367.79998779296875, 226], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": null}, {\"name\": \"value1\", \"type\": \"STRING\", \"widget\": {\"name\": \"value1\"}, \"link\": 225}], \"outputs\": [{\"name\": \"EXTRA_METADATA\", \"type\": \"EXTRA_METADATA\", \"links\": [167, 170], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"CreateExtraMetaData\"}, \"widgets_values\": [\"Pos\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]}, {\"id\": 119, \"type\": \"easy showAnything\", \"pos\": [2408.923583984375, 2572.09814453125], \"size\": [239.81918334960938, 357.0870361328125], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 170}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": null}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [[\"{\\\"Pos\\\": \\\"(Ultra-detailed DSLR photo:1.3), (professional pet grooming salon interior), (Golden Retriever with wet fluffy fur, water droplets, 8k fur texture), (Calico cat on marble table, natural sunlight), (stainless steel grooming tools, ceramic shampoo bottles, microfiber towels), soft pastel colors (mint green walls, blush pink accents), (cinematic depth of field, Fujifilm X-T4, f/2.8), photorealistic texture,perfection style, Cinematic Photography style,\\\", \\\"\\\": \\\"\\\"}\"]]}, {\"id\": 152, \"type\": \"Context Merge Big (rgthree)\", \"pos\": [1578.6474609375, 2086.99560546875], \"size\": [226.8000030517578, 466], \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"ctx_01\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 217}, {\"name\": \"ctx_02\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_03\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_04\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_05\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [220], \"slot_index\": 1}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": [223], \"slot_index\": 3}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": [221], \"slot_index\": 4}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": [222], \"slot_index\": 5}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": [219], \"slot_index\": 7}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [225], \"slot_index\": 17}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 42, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": [-114.01629638671875, 868.0133056640625], \"size\": [226.8000030517578, 202], \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}}, {\"id\": 113, \"type\": \"UpscaleModelLoader\", \"pos\": [1529.2525634765625, 1965.1983642578125], \"size\": [315, 58], \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [159], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"ESRGAN_4x.pth\"]}, {\"id\": 99, \"type\": \"VAEDecode\", \"pos\": [686.040283203125, 2142.46142578125], \"size\": [210, 46], \"flags\": {\"collapsed\": false}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 137}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 138}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [153, 211, 232], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 77, \"type\": \"UltimateSDUpscale\", \"pos\": [1918.5362548828125, 1951.04296875], \"size\": [315, 614], \"flags\": {}, \"order\": 42, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 219}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 220}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 221}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 222}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 223}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 159}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [169, 231], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui_ultimatesdupscale\", \"ver\": \"ff3fdfeee03de46d4462211cffd165d27155e858\", \"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [4, 627362334615305, \"increment\", 20, 1, \"euler\", \"normal\", 0.12, \"Linear\", 512, 512, 8, 0, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 153, \"type\": \"Image Comparer (rgthree)\", \"pos\": [846.02734375, 2832.2861328125], \"size\": [663.0813598632812, 731.4021606445312], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 231}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 232}], \"outputs\": [], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\", \"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_fisro_00009_.png&type=temp&subfolder=&rand=0.9972346913283903\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_fisro_00010_.png&type=temp&subfolder=&rand=0.8225111659462729\"}]]}, {\"id\": 138, \"type\": \"LoadImage\", \"pos\": [-2596.678955078125, 919.302734375], \"size\": [315, 314], \"flags\": {}, \"order\": 8, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [192], \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"K\\u00e9perny\\u0151k\\u00e9p 2025-02-24 185123.png\", \"image\"]}, {\"id\": 133, \"type\": \"Florence2Run\", \"pos\": [-2171.5830078125, 1037.89208984375], \"size\": [400, 352], \"flags\": {}, \"order\": 16, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 192}, {\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"link\": 193}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1}, {\"name\": \"caption\", \"type\": \"STRING\", \"links\": [194], \"slot_index\": 2}, {\"name\": \"data\", \"type\": \"JSON\", \"links\": null, \"slot_index\": 3}], \"properties\": {\"cnr_id\": \"comfyui-florence2\", \"ver\": \"1.0.3\", \"Node name for S&R\": \"Florence2Run\"}, \"widgets_values\": [\"\", \"more_detailed_caption\", false, false, 2048, 4, false, \"\", 475282495362971, \"increment\"]}, {\"id\": 136, \"type\": \"iToolsPromptStylerExtra\", \"pos\": [-1403.97119140625, 911.7665405273438], \"size\": [300, 420], \"flags\": {}, \"order\": 24, \"mode\": 2, \"inputs\": [{\"name\": \"text_positive\", \"type\": \"STRING\", \"widget\": {\"name\": \"text_positive\"}, \"link\": 195}], \"outputs\": [{\"name\": \"positive_prompt\", \"type\": \"STRING\", \"links\": [196], \"slot_index\": 0}, {\"name\": \"negative_prompt\", \"type\": \"STRING\", \"links\": [197], \"slot_index\": 1}, {\"name\": \"used_templates\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"aux_id\": \"fecsaba/ComfyUI-iTools\", \"ver\": \"0.4.9\", \"Node name for S&R\": \"iToolsPromptStylerExtra\", \"cnr_id\": \"comfyui-itools\"}, \"widgets_values\": [\"\", \"ugly, watermark\", \"Drawing.yaml\", \"none\", \"Art.yaml\", \"none\", \"artist.yaml\", \"none\", \"mood.yaml\", \"none\", null], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 137, \"type\": \"easy showAnything\", \"pos\": [-1753.4393310546875, 980.1578979492188], \"size\": [282.40643310546875, 210.21043395996094], \"flags\": {}, \"order\": 21, \"mode\": 2, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"shape\": 7, \"link\": 194}], \"outputs\": [{\"name\": \"output\", \"type\": \"*\", \"links\": [195], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [\"A close-up of a person wearing a black t-shirt with a graphic design on the front. The design features a white cat with striking green eyes peeking out from behind a torn piece of paper. The cat's paws are visible, and it appears to be in a playful pose. The person wears a gold necklace and a silver watch on their wrist. The background is plain white, highlighting the cat and the person's clothing.\"]}, {\"id\": 147, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": [-589.7310180664062, 914.842041015625], \"size\": [226.8000030517578, 106], \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"yellow\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"always one\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 108, \"type\": \"SamplerCustomAdvanced\", \"pos\": [790.0797729492188, 1993.872802734375], \"size\": [355.20001220703125, 106], \"flags\": {\"collapsed\": false}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 146}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 147}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 148}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 149}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 150}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [137], \"slot_index\": 0}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 151, \"type\": \"Reroute (rgthree)\", \"pos\": [2123.21923828125, 1769.036376953125], \"size\": [40, 30], \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": null, \"has_old_label\": true}], \"outputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 4, \"links\": [238], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 158, \"type\": \"Context Big (rgthree)\", \"pos\": [2841.6455078125, 1846.7999267578125], \"size\": [317.4000244140625, 466], \"flags\": {}, \"order\": 17, \"mode\": 4, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 238}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": null}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": null}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": [240], \"slot_index\": 7}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [239], \"slot_index\": 19}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 141, \"type\": \"Context Switch Big (rgthree)\", \"pos\": [-351.7754211425781, 2173.8974609375], \"size\": [235.1999969482422, 466], \"flags\": {\"collapsed\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"ctx_01\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 198}, {\"name\": \"ctx_02\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": 206}, {\"name\": \"ctx_03\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_04\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"ctx_05\", \"type\": \"RGTHREE_CONTEXT\", \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [199, 224], \"slot_index\": 17}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": [200]}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 149, \"type\": \"Context Big (rgthree)\", \"pos\": [1042.167724609375, 2166.87744140625], \"size\": [317.4000244140625, 466], \"flags\": {\"collapsed\": true}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"base_ctx\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 3, \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 212}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"dir\": 3, \"link\": 215}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": 213}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"dir\": 3, \"link\": 214}, {\"name\": \"latent\", \"type\": \"LATENT\", \"dir\": 3, \"link\": null}, {\"name\": \"images\", \"type\": \"IMAGE\", \"dir\": 3, \"link\": 211}, {\"name\": \"seed\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"steps\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"step_refiner\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"cfg\", \"type\": \"FLOAT\", \"dir\": 3, \"link\": null}, {\"name\": \"ckpt_name\", \"type\": [], \"dir\": 3, \"link\": null}, {\"name\": \"sampler\", \"type\": [\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\", \"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\", \"gradient_estimation\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], \"dir\": 3, \"link\": null}, {\"name\": \"scheduler\", \"type\": [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\", \"beta\", \"linear_quadratic\", \"kl_optimal\"], \"dir\": 3, \"link\": null}, {\"name\": \"clip_width\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"clip_height\", \"type\": \"INT\", \"dir\": 3, \"link\": null}, {\"name\": \"text_pos_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": 224}, {\"name\": \"text_pos_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_g\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"text_neg_l\", \"type\": \"STRING\", \"dir\": 3, \"link\": null}, {\"name\": \"mask\", \"type\": \"MASK\", \"dir\": 3, \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"dir\": 3, \"link\": null}], \"outputs\": [{\"name\": \"CONTEXT\", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"shape\": 3, \"links\": [216], \"slot_index\": 0}, {\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"POSITIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"NEGATIVE\", \"type\": \"CONDITIONING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SEED\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEPS\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"STEP_REFINER\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CKPT_NAME\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SAMPLER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"SCHEDULER\", \"type\": \"COMBO\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_POS_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_G\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"TEXT_NEG_L\", \"type\": \"STRING\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"dir\": 4, \"shape\": 3, \"links\": null}, {\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"dir\": 4, \"shape\": 3, \"links\": null}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\"}, \"widgets_values\": []}, {\"id\": 150, \"type\": \"Reroute (rgthree)\", \"pos\": [1440.7125244140625, 1946.150146484375], \"size\": [40, 30], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"label\": \" \", \"type\": \"*\", \"dir\": 3, \"link\": 216, \"has_old_label\": true}], \"outputs\": [{\"name\": \"CONTEXT\", \"label\": \" \", \"type\": \"RGTHREE_CONTEXT\", \"dir\": 4, \"links\": [217], \"slot_index\": 0, \"has_old_label\": true}], \"title\": \"CTX\", \"properties\": {\"resizable\": false, \"size\": [40, 30], \"showLabel\": true}}, {\"id\": 155, \"type\": \"SaveImageWithMetaData\", \"pos\": [3221.05810546875, 1994.283447265625], \"size\": [315, 482], \"flags\": {}, \"order\": 25, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 240}, {\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": 235}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"SaveImageWithMetaData\"}, \"widgets_values\": [\"Not_upscaled\", \"Farthest\", 0, \"png\", true, 100, false, true, false]}, {\"id\": 156, \"type\": \"CreateExtraMetaData\", \"pos\": [2827.42333984375, 2522.215087890625], \"size\": [367.79998779296875, 226], \"flags\": {}, \"order\": 22, \"mode\": 4, \"inputs\": [{\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": null}, {\"name\": \"value1\", \"type\": \"STRING\", \"widget\": {\"name\": \"value1\"}, \"link\": 239}], \"outputs\": [{\"name\": \"EXTRA_METADATA\", \"type\": \"EXTRA_METADATA\", \"links\": [235], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"CreateExtraMetaData\"}, \"widgets_values\": [\"Pos\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]}, {\"id\": 110, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": [-85.22692108154297, 2001.6812744140625], \"size\": [340.20001220703125, 190], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"dir\": 3, \"link\": 151}, {\"name\": \"clip\", \"type\": \"CLIP\", \"dir\": 3, \"link\": 152}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"dir\": 4, \"shape\": 3, \"links\": [141, 143, 212], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"dir\": 4, \"shape\": 3, \"links\": [209]}], \"properties\": {\"cnr_id\": \"rgthree-comfy\", \"ver\": \"32142fe476878a354dda6e2d4b5ea98960de3ced\", \"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": true, \"lora\": \"Detailed_Perfection_style.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"Stock_Footage_Style_XL_F1D.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux_realism_lora_comfy converted_version.safetensors\", \"strength\": 1, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 112, \"type\": \"PreviewImage\", \"pos\": [710.390380859375, 2225.689208984375], \"size\": [210, 246], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 153}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 104, \"type\": \"BasicScheduler\", \"pos\": [287.3750915527344, 2133.152099609375], \"size\": [315, 106], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 143}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [149], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 20, 0.9]}, {\"id\": 117, \"type\": \"SaveImageWithMetaData\", \"pos\": [2372.635498046875, 1977.886474609375], \"size\": [315, 482], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 169}, {\"name\": \"extra_metadata\", \"type\": \"EXTRA_METADATA\", \"shape\": 7, \"link\": 167}], \"outputs\": [], \"properties\": {\"cnr_id\": \"comfyui-imagemetadataextension\", \"ver\": \"1.1.3\", \"Node name for S&R\": \"SaveImageWithMetaData\"}, \"widgets_values\": [\"ComfyUI\", \"Farthest\", 0, \"png\", false, 100, false, true, false]}, {\"id\": 105, \"type\": \"RandomNoise\", \"pos\": [295.4716796875, 1986.357666015625], \"size\": [315, 82], \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [146]}], \"properties\": {\"cnr_id\": \"comfy-core\", \"ver\": \"0.3.15\", \"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [871123092213814, \"increment\"]}, {\"id\": 116, \"type\": \"FluxResolutionNode\", \"pos\": [-58.40528869628906, 2287.884765625], \"size\": [315, 190], \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [163], \"slot_index\": 0}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [164], \"slot_index\": 1}, {\"name\": \"resolution\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"preview\", \"type\": \"IMAGE\", \"links\": null}], \"properties\": {\"cnr_id\": \"controlaltai-nodes\", \"ver\": \"404b22d09283b2ece48da6c4e024d4d6beaecb07\", \"Node name for S&R\": \"FluxResolutionNode\"}, \"widgets_values\": [\"1.0\", \"5:7 (Balanced Portrait)\", false, \"1:1.4\"]}, {\"id\": 107, \"type\": \"easy positive\", \"pos\": [-1712.91796875, 1949.358154296875], \"size\": [400, 200], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"links\": [135], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy positive\"}, \"widgets_values\": [\"(Ultra-detailed DSLR photo:1.3), (professional pet grooming salon interior), (Golden Retriever with wet fluffy fur, water droplets, 8k fur texture), (Calico cat on marble table, natural sunlight), (stainless steel grooming tools, ceramic shampoo bottles, microfiber towels), soft pastel colors (mint green walls, blush pink accents), (cinematic depth of field, Fujifilm X-T4, f/2.8), photorealistic texture\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 101, \"type\": \"easy negative\", \"pos\": [-1296.494873046875, 1946.167236328125], \"size\": [400, 200], \"flags\": {\"collapsed\": false}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"negative\", \"type\": \"STRING\", \"links\": [176], \"slot_index\": 0}], \"properties\": {\"cnr_id\": \"comfyui-easy-use\", \"ver\": \"1.2.7\", \"Node name for S&R\": \"easy negative\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}], \"links\": [[135, 107, 0, 97, 0, \"STRING\"], [136, 96, 0, 97, 1, \"STRING\"], [137, 108, 0, 99, 0, \"LATENT\"], [138, 98, 0, 99, 1, \"VAE\"], [139, 95, 0, 100, 0, \"CLIP\"], [141, 110, 0, 103, 0, \"MODEL\"], [142, 106, 0, 103, 1, \"CONDITIONING\"], [143, 110, 0, 104, 0, \"MODEL\"], [146, 105, 0, 108, 0, \"NOISE\"], [147, 103, 0, 108, 1, \"GUIDER\"], [148, 102, 0, 108, 2, \"SAMPLER\"], [149, 104, 0, 108, 3, \"SIGMAS\"], [150, 109, 0, 108, 4, \"LATENT\"], [151, 111, 0, 110, 0, \"MODEL\"], [152, 95, 0, 110, 1, \"CLIP\"], [153, 99, 0, 112, 0, \"IMAGE\"], [159, 113, 0, 77, 5, \"UPSCALE_MODEL\"], [163, 116, 0, 109, 0, \"INT\"], [164, 116, 1, 109, 1, \"INT\"], [167, 118, 0, 117, 1, \"EXTRA_METADATA\"], [169, 77, 0, 117, 0, \"IMAGE\"], [170, 118, 0, 119, 0, \"*\"], [176, 101, 0, 121, 19, \"STRING\"], [177, 97, 0, 121, 17, \"STRING\"], [192, 138, 0, 133, 0, \"IMAGE\"], [193, 134, 0, 133, 1, \"FL2MODEL\"], [194, 133, 2, 137, 0, \"*\"], [195, 137, 0, 136, 0, \"STRING\"], [196, 136, 0, 139, 0, \"*\"], [197, 136, 1, 135, 0, \"*\"], [198, 124, 0, 141, 0, \"RGTHREE_CONTEXT\"], [199, 141, 17, 106, 1, \"STRING\"], [200, 141, 19, 100, 1, \"STRING\"], [202, 139, 0, 143, 17, \"STRING\"], [203, 135, 0, 143, 19, \"STRING\"], [204, 143, 0, 144, 0, \"*\"], [205, 144, 0, 145, 0, \"*\"], [206, 145, 0, 141, 1, \"RGTHREE_CONTEXT\"], [209, 110, 1, 106, 0, \"CLIP\"], [210, 121, 0, 124, 0, \"*\"], [211, 99, 0, 149, 7, \"IMAGE\"], [212, 110, 0, 149, 1, \"MODEL\"], [213, 106, 0, 149, 4, \"CONDITIONING\"], [214, 100, 0, 149, 5, \"CONDITIONING\"], [215, 98, 0, 149, 3, \"VAE\"], [216, 149, 0, 150, 0, \"*\"], [217, 150, 0, 152, 0, \"RGTHREE_CONTEXT\"], [219, 152, 7, 77, 0, \"IMAGE\"], [220, 152, 1, 77, 1, \"MODEL\"], [221, 152, 4, 77, 2, \"CONDITIONING\"], [222, 152, 5, 77, 3, \"CONDITIONING\"], [223, 152, 3, 77, 4, \"VAE\"], [224, 141, 17, 149, 17, \"STRING\"], [225, 152, 17, 118, 1, \"STRING\"], [231, 77, 0, 153, 0, \"IMAGE\"], [232, 99, 0, 153, 1, \"IMAGE\"], [235, 156, 0, 155, 1, \"EXTRA_METADATA\"], [238, 151, 0, 158, 0, \"RGTHREE_CONTEXT\"], [239, 158, 19, 156, 1, \"STRING\"], [240, 158, 7, 155, 0, \"IMAGE\"]], \"groups\": [{\"id\": 3, \"title\": \"Prompts\", \"bounding\": [-1726.4249267578125, 1875.7581787109375, 837.19189453125, 402.0699768066406], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"id\": 4, \"title\": \"IMG2TXT\", \"bounding\": [-2606.678955078125, 845.7027587890625, 1959.609619140625, 618.3355102539062], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"id\": 5, \"title\": \"GGUF\", \"bounding\": [-361.7754211425781, 1912.7576904296875, 1722.501953125, 773.0628662109375], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"id\": 6, \"title\": \"Upscale\", \"bounding\": [1519.2525634765625, 1877.4429931640625, 1185.050537109375, 1061.74267578125], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.826446280991736, \"offset\": [1175.4593842737936, -1968.5827371484077]}, \"node_versions\": {\"ComfyUI-Easy-Use\": \"aadbb0b38945eba3e15be6099a7f4e5c0327c175\", \"ComfyUI-GGUF\": \"5875c52f59baca3a9372d68c43a3775e21846fe0\", \"ComfyUI-Crystools\": \"72e2e9af4a6b9a58ca5d753cacff37ba1ff9bfa8\", \"comfy-core\": \"0.3.14\", \"rgthree-comfy\": \"31b784bac495160436a8cd91bf1a856cf01a738e\", \"ComfyUI-Florence2\": \"90b012e922f8bb0482bcd2ae24cdc191ec12a11f\", \"ComfyUI-iTools\": \"c1847d1aa6115bf52fec2440fa5a235235d1477f\", \"ControlAltAI-Nodes\": \"404b22d09283b2ece48da6c4e024d4d6beaecb07\", \"ComfyUI_UltimateSDUpscale\": \"ff3fdfeee03de46d4462211cffd165d27155e858\", \"ComfyUI-SaveImageWithMetaData\": \"dc9990fc20c1a8c4041cb090f07b1ffe5cb21cf2\"}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"77\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"102\": {\"sampler_name\": 0}, \"104\": {\"scheduler\": 0}, \"105\": {\"noise_seed\": 0}, \"133\": {\"seed\": 8}}, \"seed_widgets\": {\"77\": 1, \"105\": 0, \"133\": 8}}\n",
            "\n",
            "\n",
            "Az eredmények sikeresen mentve: /content/drive/MyDrive/Image/png_metadata_results.json\n",
            "\n",
            "Összesítés:\n",
            "======================================================================\n",
            "Összesen 4 érvényes PNG fájl metaadatait olvastuk be.\n"
          ]
        }
      ],
      "source": [
        "from PIL import PngImagePlugin, Image\n",
        "import os\n",
        "import json\n",
        "\n",
        "class PngValidator:\n",
        "    \"\"\"PNG fájlok érvényességének ellenőrzésére szolgáló osztály.\n",
        "\n",
        "    Ez az osztály felelős a PNG fájlok formátumának validálásáért. Ellenőrzi, hogy egy fájl\n",
        "    valóban érvényes PNG formátumú-e, függetlenül a fájl kiterjesztésétől.\n",
        "\n",
        "    Methods:\n",
        "        is_valid_png(file_path): Ellenőrzi egy fájl PNG formátumát.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def is_valid_png(file_path):\n",
        "        \"\"\"Ellenőrzi, hogy a fájl valóban PNG formátumú-e.\n",
        "\n",
        "        A metódus megnyitja a fájlt és ellenőrzi annak belső formátumát,\n",
        "        nem csak a kiterjesztést vizsgálja.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): A vizsgálandó fájl teljes elérési útja.\n",
        "\n",
        "        Returns:\n",
        "            bool: True ha a fájl valódi PNG formátumú, False egyébként.\n",
        "\n",
        "        Example:\n",
        "            >>> validator = PngValidator()\n",
        "            >>> is_valid = validator.is_valid_png(\"kep.png\")\n",
        "            >>> print(is_valid)\n",
        "            True\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                return isinstance(img, PngImagePlugin.PngImageFile) and img.format == 'PNG'\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "class PngFileHandler:\n",
        "    \"\"\"PNG fájlok és mappák kezelésére szolgáló osztály.\n",
        "\n",
        "    Ez az osztály felelős a fájlrendszer műveletek végrehajtásáért,\n",
        "    beleértve a mappák beolvasását és a PNG fájlok azonosítását.\n",
        "\n",
        "    Attributes:\n",
        "        directory_path (str): A feldolgozandó mappa elérési útja.\n",
        "\n",
        "    Methods:\n",
        "        set_directory_path(directory_path): Beállítja a feldolgozandó mappa útvonalát.\n",
        "        get_png_files(): Összegyűjti az érvényes PNG fájlokat a megadott mappából.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, directory_path=None):\n",
        "        \"\"\"Inicializálja a PngFileHandler osztályt.\n",
        "\n",
        "        Args:\n",
        "            directory_path (str, optional): A feldolgozandó mappa elérési útja.\n",
        "                                          Alapértelmezett érték: None.\n",
        "        \"\"\"\n",
        "        self.directory_path = directory_path\n",
        "\n",
        "    def set_directory_path(self, directory_path):\n",
        "        \"\"\"Beállítja a feldolgozandó mappa útvonalát.\n",
        "\n",
        "        Args:\n",
        "            directory_path (str): A feldolgozandó mappa elérési útja.\n",
        "        \"\"\"\n",
        "        self.directory_path = directory_path\n",
        "\n",
        "    def get_png_files(self):\n",
        "        \"\"\"Összegyűjti az érvényes PNG fájlokat a megadott mappából.\n",
        "\n",
        "        A metódus ellenőrzi a megadott mappában található összes fájlt,\n",
        "        és csak azokat a fájlokat adja vissza, amelyek valóban PNG formátumúak.\n",
        "\n",
        "        Returns:\n",
        "            list: Érvényes PNG fájlok teljes elérési útjainak listája.\n",
        "\n",
        "        Note:\n",
        "            - Ha nincs megadva mappa útvonal, üres listával tér vissza\n",
        "            - Ha a mappa nem létezik, üres listával tér vissza\n",
        "            - Figyelmeztetést ad ki, ha talál olyan fájlt, ami .png kiterjesztésű,\n",
        "              de nem valódi PNG formátumú\n",
        "        \"\"\"\n",
        "        if not self.directory_path:\n",
        "            print(\"Nincs megadva mappa útvonal!\")\n",
        "            return []\n",
        "\n",
        "        if not os.path.exists(self.directory_path):\n",
        "            print(f\"A megadott mappa nem létezik: {self.directory_path}\")\n",
        "            return []\n",
        "\n",
        "        png_files = []\n",
        "        for filename in os.listdir(self.directory_path):\n",
        "            file_path = os.path.join(self.directory_path, filename)\n",
        "            if PngValidator.is_valid_png(file_path):\n",
        "                png_files.append(file_path)\n",
        "            elif filename.lower().endswith('.png'):\n",
        "                print(f\"\\nFigyelmeztetés: A fájl '.png' kiterjesztésű, de nem valódi PNG: {filename}\")\n",
        "\n",
        "        return png_files\n",
        "\n",
        "class MetadataReader:\n",
        "    \"\"\"PNG fájlok metaadatainak olvasására szolgáló osztály.\n",
        "\n",
        "    Ez az osztály felelős a PNG fájlok metaadatainak kinyeréséért és\n",
        "    megjelenítéséért. A metaadatok között szerepelhetnek például a készítő,\n",
        "    a létrehozás dátuma, és egyéb egyedi információk.\n",
        "\n",
        "    Methods:\n",
        "        read_metadata(file_path): Beolvassa és megjeleníti egy PNG fájl metaadatait.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def read_metadata(file_path):\n",
        "        \"\"\"Beolvassa egy PNG fájl metaadatait.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): A PNG fájl teljes elérési útja.\n",
        "\n",
        "        Returns:\n",
        "            dict: A metaadatok szótár formátumban, ahol a kulcsok a metaadat mezők nevei,\n",
        "                 az értékek pedig a hozzájuk tartozó értékek.\n",
        "                 Hiba esetén None-nal tér vissza.\n",
        "                 Ha nincsenek metaadatok, üres szótárral tér vissza.\n",
        "\n",
        "        Note:\n",
        "            A metódus a következő eseteket kezeli:\n",
        "            - Sikeres beolvasás esetén kiírja a metaadatokat\n",
        "            - Ha nincsenek metaadatok, ezt jelzi\n",
        "            - Ha a fájl nem található, hibaüzenetet ad\n",
        "            - Egyéb hibák esetén hibaüzenetet ad\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                metadata = img.text\n",
        "                if metadata:\n",
        "                    print(f\"\\nMetaadatok a következő fájlhoz: {os.path.basename(file_path)}\")\n",
        "                    print(\"-\" * 50)\n",
        "                    for k, v in metadata.items():\n",
        "                        print(f\"**{k}**:\\n{v}\\n\")\n",
        "                    return metadata\n",
        "                else:\n",
        "                    print(f\"\\nNem találtunk metaadatokat a következő fájlban: {os.path.basename(file_path)}\")\n",
        "                    return {}\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"A fájl nem található: {file_path}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Hiba történt a következő fájlnál {os.path.basename(file_path)}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "class PngMetadataProcessor:\n",
        "    \"\"\"PNG fájlok metaadatainak feldolgozására szolgáló fő osztály.\n",
        "\n",
        "    Ez az osztály koordinálja a teljes feldolgozási folyamatot, összekapcsolva\n",
        "    a fájlkezelést és a metaadat-olvasást. Egy megadott mappában található összes\n",
        "    PNG fájlt feldolgozza és összegyűjti azok metaadatait.\n",
        "\n",
        "    Attributes:\n",
        "        file_handler (PngFileHandler): A fájlkezelésért felelős objektum.\n",
        "\n",
        "    Methods:\n",
        "        process_directory(): Feldolgozza a megadott mappában található összes PNG fájlt.\n",
        "        save_results_to_json(results): Elmenti az eredményeket JSON fájlba.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, directory_path=None):\n",
        "        \"\"\"Inicializálja a PngMetadataProcessor osztályt.\n",
        "\n",
        "        Args:\n",
        "            directory_path (str, optional): A feldolgozandó mappa elérési útja.\n",
        "                                          Alapértelmezett érték: None.\n",
        "        \"\"\"\n",
        "        self.file_handler = PngFileHandler(directory_path)\n",
        "\n",
        "    def process_directory(self):\n",
        "        \"\"\"Feldolgozza a megadott mappában található összes PNG fájlt.\n",
        "\n",
        "        A metódus végigmegy a megadott mappában található összes PNG fájlon,\n",
        "        és összegyűjti azok metaadatait. A folyamat során:\n",
        "        1. Azonosítja az érvényes PNG fájlokat\n",
        "        2. Beolvassa minden fájl metaadatait\n",
        "        3. Összesíti az eredményeket\n",
        "\n",
        "        Returns:\n",
        "            dict: Egy szótár, ahol a kulcsok a fájlnevek, az értékek pedig\n",
        "                 a hozzájuk tartozó metaadatok szótár formátumban.\n",
        "        \"\"\"\n",
        "        print(f\"\\nPNG fájlok keresése a következő mappában: {self.file_handler.directory_path}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        png_files = self.file_handler.get_png_files()\n",
        "        results = {}\n",
        "\n",
        "        for file_path in png_files:\n",
        "            metadata = MetadataReader.read_metadata(file_path)\n",
        "            if metadata:\n",
        "                results[os.path.basename(file_path)] = metadata\n",
        "\n",
        "        if not results:\n",
        "            print(\"\\nNem találtunk érvényes PNG fájlokat a megadott mappában.\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def save_results_to_json(self, results):\n",
        "        \"\"\"Elmenti az eredményeket JSON fájlba.\n",
        "\n",
        "        Args:\n",
        "            results (dict): A mentendő metaadatok szótár formátumban.\n",
        "\n",
        "        Note:\n",
        "            A fájl neve 'png_metadata_results.json' lesz, és az Image mappába kerül mentésre.\n",
        "            Ha a fájl már létezik, felülírja azt.\n",
        "        \"\"\"\n",
        "        if not results:\n",
        "            print(\"\\nNincs menthető adat.\")\n",
        "            return\n",
        "\n",
        "        output_path = os.path.join(self.file_handler.directory_path, \"png_metadata_results.json\")\n",
        "        try:\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"\\nAz eredmények sikeresen mentve: {output_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nHiba történt a fájl mentése közben: {str(e)}\")\n",
        "\n",
        "# Példa használat és tesztelés\n",
        "if __name__ == \"__main__\":\n",
        "    # Példa a program használatára\n",
        "    processor = PngMetadataProcessor(\"/content/drive/MyDrive/Image/\")\n",
        "    all_metadata = processor.process_directory()\n",
        "\n",
        "    # Eredmények mentése JSON fájlba\n",
        "    processor.save_results_to_json(all_metadata)\n",
        "\n",
        "    # Összesítés\n",
        "    if all_metadata:\n",
        "        print(\"\\nÖsszesítés:\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Összesen {len(all_metadata)} érvényes PNG fájl metaadatait olvastuk be.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hmq4bU11g0Z"
      },
      "source": [
        "## Pozitív prompt kiszedése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pngl55JO2FS2"
      },
      "source": [
        "### Leírás kiválasztása"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oww5fZSm1_-x",
        "outputId": "af81c9d6-64e4-4b62-c178-fe0a7d810945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully extracted 'Pos' values to /content/drive/MyDrive/Image/desc.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import sys\n",
        "\n",
        "def extract_pos_from_parameters(input_json_path, output_json_path):\n",
        "    \"\"\"\n",
        "    Extracts the 'Pos' value from the 'parameters' string in the input JSON and saves it to a new JSON file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(input_json_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {input_json_path}\")\n",
        "        return False\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Invalid JSON in input file {input_json_path}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An unexpected error occurred: {type(e).__name__} - {e}\")\n",
        "        return False\n",
        "\n",
        "    pos_data = {}\n",
        "    pos_pattern = re.compile(r'Pos:\\s*([\\s\\S]*?)(?:,\\n|$)')  # Regex pattern to extract the Pos value\n",
        "\n",
        "    for image_filename, image_data in data.items():\n",
        "        if 'parameters' in image_data and isinstance(image_data['parameters'], str):\n",
        "            match = pos_pattern.search(image_data['parameters'])\n",
        "            if match:\n",
        "                pos_value = match.group(1).strip()  # Get the matched Pos value and strip whitespace\n",
        "                pos_data[image_filename] = pos_value\n",
        "            else:\n",
        "                print(f\"Warning: No 'Pos' key found in parameters for {image_filename}\")\n",
        "                pos_data[image_filename] = \"\"  # Üres string, ha nincs 'Pos'\n",
        "        else:\n",
        "            print(f\"Warning: No 'parameters' string found for {image_filename}\")\n",
        "            pos_data[image_filename] = \"\"  # Üres string, ha nincs 'parameters'\n",
        "\n",
        "    try:\n",
        "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pos_data, f, indent=2)  # Szebb JSON formázás\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Could not write to output file {output_json_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if len(sys.argv) != 3:\n",
        "        print(\"Usage: python3 extract_pos.py <input_json_file> <output_json_file>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    input_file = \"/content/drive/MyDrive/Image/png_metadata_results.json\"\n",
        "    output_file = \"/content/drive/MyDrive/Image/desc.json\"\n",
        "\n",
        "    if extract_pos_from_parameters(input_file, output_file):\n",
        "        print(f\"Successfully extracted 'Pos' values to {output_file}\")\n",
        "    else:\n",
        "        print(\"Extraction failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LJQOZyzHWMN"
      },
      "source": [
        "### Szöveg generálás"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKZmIQqHQOm"
      },
      "source": [
        "### Tisztítás"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "kt773P8ZF_X9",
        "outputId": "b095daad-3a81-43a9-d3fd-bf81cb9554c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "A 'desc.json' megtalálva a projektkönyvtárban, folytatom a feldolgozást...\n",
            "A megtisztított JSON fájl elmentve a projektkönyvtárba ('cleaned_output.json'), és letöltheted!\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_943e7337-f245-4701-9a5f-9a4d665c70b5\", \"cleaned_output.json\", 2181)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Szükséges könyvtárak importálása\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive, files\n",
        "\n",
        "# 1. Google Drive csatolása\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Projekt könyvtár és fájlok beállítása\n",
        "project_dir = '/content/drive/MyDrive/Image'\n",
        "input_filename = os.path.join(project_dir, 'desc.json')\n",
        "output_filename = os.path.join(project_dir, 'cleaned_output.json')\n",
        "\n",
        "# 3. Ellenőrzés, hogy a desc.json létezik-e\n",
        "if not os.path.exists(input_filename):\n",
        "    print(\"Hiba: A 'desc.json' nem található a projektkönyvtárban!\")\n",
        "    print(\"Kérlek, töltsd fel a fájlt, ha szükséges!\")\n",
        "    uploaded = files.upload()\n",
        "    for fname, content in uploaded.items():\n",
        "        with open(input_filename, 'wb') as f:\n",
        "            f.write(content)\n",
        "    print(\"Fájl feltöltve a projektkönyvtárba!\")\n",
        "else:\n",
        "    print(\"A 'desc.json' megtalálva a projektkönyvtárban, folytatom a feldolgozást...\")\n",
        "\n",
        "# 4. JSON fájl betöltése\n",
        "with open(input_filename, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 5. Promptok tisztítása függvény\n",
        "def clean_prompt(prompt):\n",
        "    # Perjelek cseréje szóközre\n",
        "    cleaned = prompt.replace('/', ' ')\n",
        "    # Zárójelek eltávolítása\n",
        "    cleaned = cleaned.replace('(', '').replace(')', '')\n",
        "    # Többszörös szóközök eltávolítása\n",
        "    cleaned = ' '.join(cleaned.split())\n",
        "    return cleaned.strip()\n",
        "\n",
        "# 6. Minden prompt megtisztítása\n",
        "cleaned_data = {}\n",
        "for filename, prompt in data.items():\n",
        "    cleaned_prompt = clean_prompt(prompt)\n",
        "    cleaned_data[filename] = cleaned_prompt\n",
        "\n",
        "# 7. Megtisztított JSON mentése a projektkönyvtárba\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    json.dump(cleaned_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# 8. Az új fájl letöltése\n",
        "print(\"A megtisztított JSON fájl elmentve a projektkönyvtárba ('cleaned_output.json'), és letöltheted!\")\n",
        "files.download(output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIejmlPUQZFl"
      },
      "source": [
        "### **SEO generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "HXyg0RIZQX-a",
        "outputId": "71c95e52-7eec-4d1f-90ae-e6ea0db1b0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Csatolás a Google Drive-hoz...\n",
            "Mounted at /content/drive\n",
            "A '/content/drive/MyDrive/Image/cleaned_output.json' megtalálva, betöltés...\n",
            "Betöltés a 'facebook/bart-large-cnn' modellhez a leírásokhoz...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 80, but your input_length is only 69. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SEO leírások ellenőrzése és generálása...\n",
            "Átalakítás szótárrá és leírás generálása: ComfyUI_00001_ (2).png...\n",
            "SEO leírás generálása a promptból (hossz: 717 karakter)...\n",
            "Szűrt prompt: 'a beautiful blonde woman walking in an urban city setting her long hair flowing elegantly in the wind highly detailed facial features with a touch of autumn leaves gently swirling around her and art by greg rutkowski and loish. on on the woman's face and hair of to the and by and stills. skin and for in the' (308 karakter)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your max_length is set to 80, but your input_length is only 58. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generált leírás: 'A beautiful blonde woman walking in an urban city setting her long hair flowing elegantly the wind. highly detailed facial features with a touch of autumn leaves gently swirling around her.' (189 karakter)\n",
            "Átalakítás szótárrá és leírás generálása: ComfyUI_00005_.png...\n",
            "SEO leírás generálása a promptból (hossz: 457 karakter)...\n",
            "Szűrt prompt: 'a white cat with bright green peeking out from behind a torn piece of paper highly detailed fur playful and curious expression paws in a playful pose and set against a plain white whiskers and claws art by albert hirai and david revoy. around the edges to depth.' (262 karakter)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your max_length is set to 80, but your input_length is only 59. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generált leírás: 'A white cat with bright green peeking out from behind a torn piece of paper. highly detailed fur playful and curious expression paws in pose.' (141 karakter)\n",
            "Átalakítás szótárrá és leírás generálása: ComfyUI_00013_.png...\n",
            "SEO leírás generálása a promptból (hossz: 463 karakter)...\n",
            "Szűrt prompt: 'a white cat with bright green peeking out from behind a torn piece of black paper highly detailed fur playful and curious expression paws in a playful pose and set against a plain black whiskers and claws art by albert hirai and david revoy. around the edges to depth.' (268 karakter)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your max_length is set to 80, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generált leírás: 'A white cat with bright green peeking out from behind a torn piece of black paper. highly detailed fur playful and curious expression paws in pose.' (147 karakter)\n",
            "Átalakítás szótárrá és leírás generálása: ComfyUI_00006_ (1).png...\n",
            "SEO leírás generálása a promptból (hossz: 422 karakter)...\n",
            "Szűrt prompt: 'dslr photo:1.3 professional pet grooming salon interior retriever with wet fluffy fur water droplets fur calico cat on marble table sunlight stainless steel grooming tools ceramic shampoo bottles microfiber towels pastel mint green walls blush pink accents of fujifilm x-t4' (273 karakter)\n",
            "Generált leírás: '3 professional pet grooming salon interior. Pastel mint green walls blush pink accents of fujifilm x-t4.' (104 karakter)\n",
            "Betöltés a 'facebook/bart-large-cnn' modellhez a címekhez...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SEO címek ellenőrzése és generálása...\n",
            "Feldolgozás: ComfyUI_00001_ (2).png...\n",
            "SEO cím generálása a promptból (hossz: 717 karakter)...\n",
            "Generált cím: 'A beautiful blonde woman walking in an urban city setting her long' (66 karakter)\n",
            "Feldolgozás: ComfyUI_00005_.png...\n",
            "SEO cím generálása a promptból (hossz: 457 karakter)...\n",
            "Generált cím: 'White cat with striking bright green eyes peeking out from behind' (65 karakter)\n",
            "Feldolgozás: ComfyUI_00013_.png...\n",
            "SEO cím generálása a promptból (hossz: 463 karakter)...\n",
            "Generált cím: 'White cat with striking bright green eyes peeking out from behind' (65 karakter)\n",
            "Feldolgozás: ComfyUI_00006_ (1).png...\n",
            "SEO cím generálása a promptból (hossz: 422 karakter)...\n",
            "Generált cím: 'Fujifilm X-T4 is an ultra' (25 karakter)\n",
            "Frissített fájl mentése...\n",
            "A '/content/drive/MyDrive/Image/cleaned_output.json' frissítve, letöltheted!\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_072f276d-e8d6-43d1-803a-769b2345c68b\", \"cleaned_output.json\", 3255)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Szükséges könyvtárak importálása\n",
        "from google.colab import drive, files\n",
        "import json\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "class FileManager:\n",
        "    \"\"\"Osztály a Google Drive fájlkezeléséhez és JSON műveletekhez.\"\"\"\n",
        "\n",
        "    def __init__(self, project_dir='/content/drive/MyDrive/Image', filename='cleaned_output.json'):\n",
        "        \"\"\"Inicializálja a fájlkezelőt a megadott könyvtárral és fájlnévvel.\"\"\"\n",
        "        self.project_dir = project_dir\n",
        "        self.filename = os.path.join(project_dir, filename)\n",
        "        self.data = None\n",
        "\n",
        "    def mount_drive(self):\n",
        "        \"\"\"Csatolja a Google Drive-ot a Colab környezethez.\"\"\"\n",
        "        print(\"Csatolás a Google Drive-hoz...\")\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    def load_json(self):\n",
        "        \"\"\"Betölti a JSON fájlt, ha létezik, különben hibát jelez.\"\"\"\n",
        "        if not os.path.exists(self.filename):\n",
        "            print(f\"Hiba: A '{self.filename}' nem található a projektkönyvtárban!\")\n",
        "            raise FileNotFoundError(\"Kérlek, futtasd az előző szkriptet először!\")\n",
        "        print(f\"A '{self.filename}' megtalálva, betöltés...\")\n",
        "        with open(self.filename, 'r', encoding='utf-8') as f:\n",
        "            self.data = json.load(f)\n",
        "        return self.data\n",
        "\n",
        "    def save_json(self):\n",
        "        \"\"\"Visszaírja a frissített adatokat a JSON fájlba.\"\"\"\n",
        "        print(\"Frissített fájl mentése...\")\n",
        "        with open(self.filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def download_file(self):\n",
        "        \"\"\"Letölti a frissített JSON fájlt a böngészőbe.\"\"\"\n",
        "        print(f\"A '{self.filename}' frissítve, letöltheted!\")\n",
        "        files.download(self.filename)\n",
        "\n",
        "class SEOGenerator:\n",
        "    \"\"\"Osztály SEO leírások generálására, stílus- és technikai részletek nélkül.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name='facebook/bart-large-cnn'):\n",
        "        \"\"\"Inicializálja a generátort a megadott modellel.\"\"\"\n",
        "        print(f\"Betöltés a '{model_name}' modellhez a leírásokhoz...\")\n",
        "        self.summarizer = pipeline(\"summarization\", model=model_name)\n",
        "        # Stílus- és technikai kulcsszavak kiszűrése\n",
        "        self.technical_style_terms = {\n",
        "            \"8k\", \"resolution\", \"cinematic\", \"photorealistic\", \"hyperrealism\", \"dynamic\", \"motion\", \"capture\",\n",
        "            \"crisp\", \"vibrant\", \"colors\", \"high\", \"detail\", \"textures\", \"sharp\", \"focus\", \"depth\", \"field\",\n",
        "            \"effect\", \"emphasize\", \"subject\", \"warm\", \"golden\", \"hour\", \"tones\", \"clean\", \"polished\", \"finish\",\n",
        "            \"inspired\", \"high-fashion\", \"photography\", \"film\", \"stills\", \"ultra-detailed\", \"texture\", \"lifelike\",\n",
        "            \"eyes\", \"soft\", \"bokeh\", \"effects\", \"lights\", \"background\", \"perfection\", \"style\", \"DSLR\", \"photo\",\n",
        "            \"Fujifilm\", \"X-T4\", \"f\", \"2.8\", \"natural\", \"lighting\", \"composition\", \"variety\", \"conditions\",\n",
        "            \"Adobe\", \"After\", \"Effects\", \"software\", \"realistic\", \"striking\", \"visible\", \"enhance\"\n",
        "        }\n",
        "\n",
        "    def filter_technical_style_terms(self, prompt):\n",
        "        \"\"\"Eltávolítja a stílus- és technikai kulcsszavakat a promptból.\"\"\"\n",
        "        words = prompt.lower().split()\n",
        "        filtered_words = [word for word in words if word not in self.technical_style_terms]\n",
        "        return \" \".join(filtered_words)\n",
        "\n",
        "    def generate_seo_description(self, prompt):\n",
        "        \"\"\"Generál egy maximum 500 karakteres SEO leírást a promptból, stílus- és technikai részletek nélkül.\"\"\"\n",
        "        print(f\"SEO leírás generálása a promptból (hossz: {len(prompt)} karakter)...\")\n",
        "        # Technikai és stílus részletek kiszűrése\n",
        "        filtered_prompt = self.filter_technical_style_terms(prompt)\n",
        "        print(f\"Szűrt prompt: '{filtered_prompt}' ({len(filtered_prompt)} karakter)\")\n",
        "        # Rövid összefoglaló generálása, a fő témára fókuszálva\n",
        "        summary = self.summarizer(filtered_prompt, max_length=80, min_length=20, do_sample=False)[0]['summary_text']\n",
        "        seo_desc = summary.strip()[:500]\n",
        "        # Redundancia eltávolítása\n",
        "        words = seo_desc.split()\n",
        "        seo_desc = \" \".join(sorted(set(words), key=words.index))[:500]\n",
        "        print(f\"Generált leírás: '{seo_desc}' ({len(seo_desc)} karakter)\")\n",
        "        return seo_desc\n",
        "\n",
        "class SEOTitleGenerator:\n",
        "    \"\"\"Osztály SEO címek generálására a promptból, a fő témára fókuszálva.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name='facebook/bart-large-cnn'):\n",
        "        \"\"\"Inicializálja a címgenerátort a megadott modellel.\"\"\"\n",
        "        print(f\"Betöltés a '{model_name}' modellhez a címekhez...\")\n",
        "        self.summarizer = pipeline(\"summarization\", model=model_name)\n",
        "\n",
        "    def generate_seo_title(self, prompt):\n",
        "        \"\"\"Generál egy maximum 100 karakteres SEO címet a promptból, a fő témára koncentrálva.\"\"\"\n",
        "        print(f\"SEO cím generálása a promptból (hossz: {len(prompt)} karakter)...\")\n",
        "        short_prompt = \" \".join(prompt.split()[:50])\n",
        "        input_text = f\"Summarize the main subject of: {short_prompt}. Focus on the key subject, keep it short, max 100 characters.\"\n",
        "        summary = self.summarizer(input_text, max_length=15, min_length=5, do_sample=False)[0]['summary_text']\n",
        "        seo_title = summary.strip()[:100]\n",
        "        if len(seo_title) == 100 and not seo_title.endswith('.'):\n",
        "            seo_title = seo_title[:-1] + '.'\n",
        "        print(f\"Generált cím: '{seo_title}' ({len(seo_title)} karakter)\")\n",
        "        return seo_title\n",
        "\n",
        "def main():\n",
        "    \"\"\"Fő függvény az osztályok használatához és a folyamat vezérléséhez.\"\"\"\n",
        "    file_manager = FileManager()\n",
        "    file_manager.mount_drive()\n",
        "    data = file_manager.load_json()\n",
        "\n",
        "    seo_generator = SEOGenerator()\n",
        "    print(\"SEO leírások ellenőrzése és generálása...\")\n",
        "    for filename, entry in data.items():\n",
        "        if isinstance(entry, dict):\n",
        "            if \"seo_description\" not in entry or len(entry[\"seo_description\"]) > 500:\n",
        "                print(f\"Frissítés szükséges: {filename}...\")\n",
        "                entry[\"seo_description\"] = seo_generator.generate_seo_description(entry[\"prompt\"])\n",
        "        else:\n",
        "            print(f\"Átalakítás szótárrá és leírás generálása: {filename}...\")\n",
        "            prompt = entry\n",
        "            seo_desc = seo_generator.generate_seo_description(prompt)\n",
        "            data[filename] = {\"prompt\": prompt, \"seo_description\": seo_desc}\n",
        "\n",
        "    seo_title_generator = SEOTitleGenerator()\n",
        "    print(\"SEO címek ellenőrzése és generálása...\")\n",
        "    for filename, entry in data.items():\n",
        "        print(f\"Feldolgozás: {filename}...\")\n",
        "        seo_title = seo_title_generator.generate_seo_title(entry[\"prompt\"])\n",
        "        entry[\"seo_title\"] = seo_title\n",
        "\n",
        "    file_manager.data = data\n",
        "    file_manager.save_json()\n",
        "    file_manager.download_file()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnb3aaJLNm5u"
      },
      "source": [
        "### Képfelismerés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Nb3EizjJHqJa",
        "outputId": "f8b63d2c-5332-4820-a6b2-e08735bd779a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Figyelmeztetés: GPU nem érhető el. A feldolgozás lassabb lehet.\n",
            "Google Drive csatolása...\n",
            "Mounted at /content/drive\n",
            "Talált képek: ['ComfyUI_00001_ (2).png', 'ComfyUI_00005_.png', 'ComfyUI_00013_.png', 'ComfyUI_00006_ (1).png']\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-37bc0abd7a84>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-37bc0abd7a84>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# BLIP modell betöltése (egyszer, optimalizálás)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlipProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Salesforce/blip-image-captioning-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlipForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Salesforce/blip-image-captioning-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GPU-ra helyezzük\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Képek feldolgozása\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3109\u001b[0m                 )\n\u001b[0;32m-> 3110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "class FileManager:\n",
        "    def __init__(self, project_dir='/content/drive/MyDrive/Image', filename='cleaned_output.json'):\n",
        "        self.project_dir = project_dir\n",
        "        self.filename = os.path.join(project_dir, filename)\n",
        "        self.data = {}\n",
        "\n",
        "    def mount_drive(self):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    def load_json(self):\n",
        "        if os.path.exists(self.filename):\n",
        "            try:\n",
        "                with open(self.filename, 'r', encoding='utf-8') as f:\n",
        "                    self.data = json.load(f)\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Figyelmeztetés: '{self.filename}' érvénytelen JSON fájl.\")\n",
        "                self.data = {}\n",
        "        else:\n",
        "            print(f\"'{self.filename}' nem található. Új fájl lesz létrehozva.\")\n",
        "        return self.data\n",
        "\n",
        "    def save_json(self):\n",
        "        try:\n",
        "            with open(self.filename, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.data, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"'{self.filename}' mentve!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Hiba a fájl mentése közben: {e}\")\n",
        "\n",
        "    def list_images(self):\n",
        "        if not os.path.exists(self.project_dir):\n",
        "            print(f\"Hiba: '{self.project_dir}' könyvtár nem található.\")\n",
        "            return []\n",
        "        return [f for f in os.listdir(self.project_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "class ImageDescriber:\n",
        "    def __init__(self, processor, model):\n",
        "        self.processor = processor\n",
        "        self.model = model\n",
        "\n",
        "    def load_image(self, image_path):\n",
        "        try:\n",
        "            return Image.open(image_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Hiba a(z) '{image_path}' betöltése közben: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_description(self, image_path):\n",
        "        image = self.load_image(image_path)\n",
        "        if image is None:\n",
        "            return \"Nem sikerült betölteni a képet.\"\n",
        "        inputs = self.processor(image, return_tensors=\"pt\").to('cuda')\n",
        "        out = self.model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=500,  # Célzottan 450-500 karakter körüli leírás\n",
        "            num_beams=3,         # Több variáció a részletesebb leírásért\n",
        "            length_penalty=2.8,  # Erősebb ösztönzés hosszabb szövegre\n",
        "            no_repeat_ngram_size=2,\n",
        "            do_sample=False,     # Következetes generálás\n",
        "            early_stopping=False # Ne álljon meg korán\n",
        "        )\n",
        "        desc = self.processor.decode(out[0], skip_special_tokens=True)\n",
        "        return desc\n",
        "\n",
        "def main():\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"Figyelmeztetés: GPU nem elérhető. A feldolgozás lassabb lehet.\")\n",
        "    else:\n",
        "        print(\"GPU észlelve. GPU-t használjuk a feldolgozáshoz.\")\n",
        "\n",
        "    file_manager = FileManager()\n",
        "    file_manager.mount_drive()\n",
        "    data = file_manager.load_json()\n",
        "    image_files = file_manager.list_images()\n",
        "\n",
        "    if not image_files:\n",
        "        print(\"Nincsenek képek a megadott könyvtárban.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Talált képek: {image_files}\")\n",
        "\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to('cuda')\n",
        "    describer = ImageDescriber(processor, model)\n",
        "\n",
        "    for filename in image_files:\n",
        "        image_path = os.path.join(file_manager.project_dir, filename)\n",
        "        print(f\"Feldolgozás: {filename}...\")\n",
        "\n",
        "        try:\n",
        "            prompt = data.get(filename, {}).get(\"prompt\", None)  # Csak tárolásra, nem használatra\n",
        "            image_desc = describer.generate_description(image_path)\n",
        "            print(f\"{filename} leírása: {image_desc} (Hossz: {len(image_desc)})\")\n",
        "\n",
        "            processed_at = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            if filename not in data:\n",
        "                data[filename] = {}\n",
        "            data[filename].update({\n",
        "                \"prompt\": prompt or \"Nincs megadva prompt\",\n",
        "                \"image_description\": image_desc,\n",
        "                \"link\": \"\",\n",
        "                \"processed_at\": processed_at,\n",
        "                \"uploaded_at\": \"\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Hiba a(z) '{filename}' feldolgozása közben: {e}\")\n",
        "\n",
        "    file_manager.data = data\n",
        "    file_manager.save_json()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9guHDxYQatt"
      },
      "source": [
        "# Régi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zQQ-J8V1g0b",
        "outputId": "4149d3b7-7bee-45a1-a720-d61dfd982748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully extracted 'Pos' values to /content/drive/MyDrive/Image/desc.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import sys\n",
        "\n",
        "def extract_pos_from_parameters(input_json_path, output_json_path):\n",
        "    \"\"\"\n",
        "    Extracts the 'Pos' value from the 'parameters' string in the input JSON and saves it to a new JSON file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(input_json_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {input_json_path}\")\n",
        "        return False\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Invalid JSON in input file {input_json_path}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An unexpected error occurred: {type(e).__name__} - {e}\")\n",
        "        return False\n",
        "\n",
        "    pos_data = {}\n",
        "    pos_pattern = re.compile(r'Pos:\\s*([\\s\\S]*?)(?:,\\n|$)')  # Regex pattern to extract the Pos value\n",
        "\n",
        "    for image_filename, image_data in data.items():\n",
        "        if 'parameters' in image_data and isinstance(image_data['parameters'], str):\n",
        "            match = pos_pattern.search(image_data['parameters'])\n",
        "            if match:\n",
        "                pos_value = match.group(1).strip()  # Get the matched Pos value and strip whitespace\n",
        "                pos_data[image_filename] = pos_value\n",
        "            else:\n",
        "                print(f\"Warning: No 'Pos' key found in parameters for {image_filename}\")\n",
        "                pos_data[image_filename] = \"\"  # Üres string, ha nincs 'Pos'\n",
        "        else:\n",
        "            print(f\"Warning: No 'parameters' string found for {image_filename}\")\n",
        "            pos_data[image_filename] = \"\"  # Üres string, ha nincs 'parameters'\n",
        "\n",
        "    try:\n",
        "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pos_data, f, indent=2)  # Szebb JSON formázás\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Could not write to output file {output_json_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if len(sys.argv) != 3:\n",
        "        print(\"Usage: python3 extract_pos.py <input_json_file> <output_json_file>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    input_file = \"/content/drive/MyDrive/Image/png_metadata_results.json\"\n",
        "    output_file = \"/content/drive/MyDrive/Image/desc.json\"\n",
        "\n",
        "    if extract_pos_from_parameters(input_file, output_file):\n",
        "        print(f\"Successfully extracted 'Pos' values to {output_file}\")\n",
        "    else:\n",
        "        print(\"Extraction failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jscbIT_bnuAe"
      },
      "source": [
        "## Előkészítés feltöltéshez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "lHQqtL4l1g0c",
        "outputId": "247148cf-26ad-4f1e-e66c-4820de917df0"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5089494e2622>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Define the input and output directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from transformers import pipeline\n",
        "from google.colab import drive  # Import for Google Drive integration\n",
        "from dotenv import load_dotenv  # For handling environment variables\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the input and output directories\n",
        "INPUT_FILE_PATH = \"/content/drive/MyDrive/Image/desc.json\"\n",
        "OUTPUT_DIRECTORY = \"/content/drive/MyDrive/Image\"\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Securely get the Hugging Face token from the environment variable\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\") or None\n",
        "\n",
        "# Load input data from desc.json\n",
        "def load_data(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
        "            return json.load(input_file)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {file_path} was not found.\")\n",
        "        return {}\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: The file {file_path} is not valid JSON.\")\n",
        "        return {}\n",
        "\n",
        "data = load_data(INPUT_FILE_PATH)\n",
        "\n",
        "if not data:\n",
        "    print(\"No data to process. Exiting.\")\n",
        "else:\n",
        "    # Language model for rewriting descriptions\n",
        "    rewriter = pipeline(\"text2text-generation\", model=\"t5-base\")\n",
        "\n",
        "    # Keyword extraction model (using bloomberg/KeyBART)\n",
        "    keyword_extractor = pipeline(\"text2text-generation\", model=\"bloomberg/KeyBART\", tokenizer=\"bloomberg/KeyBART\", token=HF_TOKEN)\n",
        "\n",
        "    # Function to clean and rewrite the description\n",
        "    def clean_and_rewrite_description(description):\n",
        "        \"\"\"\n",
        "        Clean up the raw description and rewrite it into a coherent, SEO-friendly format.\n",
        "        \"\"\"\n",
        "        # Remove unwanted characters and split into parts\n",
        "        cleaned_parts = [part.strip().capitalize() for part in re.sub(r'[()\\[\\]{}<>/]', '', description).split(\",\") if part.strip()]\n",
        "\n",
        "        # Use the language model to rewrite the description\n",
        "        rewritten_description = rewriter(\". \".join(cleaned_parts), max_length=500, truncation=True)[0]['generated_text']\n",
        "\n",
        "        # Post-process the rewritten description: ensure proper capitalization and no repetitions\n",
        "        final_description_parts = []\n",
        "        seen_sentences = set()\n",
        "        for sentence in rewritten_description.split(\".\"):\n",
        "            sentence = sentence.strip()\n",
        "            if sentence and sentence not in seen_sentences and len(sentence) > 10:\n",
        "                seen_sentences.add(sentence)\n",
        "                final_description_parts.append(sentence.capitalize())\n",
        "\n",
        "        # Combine rewritten description with character limit\n",
        "        final_description = []\n",
        "        current_length = 0\n",
        "        for sentence in final_description_parts:\n",
        "            if current_length + len(sentence) + 1 <= 500:\n",
        "                final_description.append(sentence)\n",
        "                current_length += len(sentence) + 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return \". \".join(final_description).strip()\n",
        "\n",
        "    # Function to check relevance of a tag to the description\n",
        "    def is_relevant_tag(tag, description):\n",
        "        \"\"\"\n",
        "        Check if the tag is relevant to the description.\n",
        "        A tag is considered relevant if it appears in the cleaned description or closely related content.\n",
        "        \"\"\"\n",
        "        normalized_description = re.sub(r'[^\\w\\s]', '', description.lower())  # Remove punctuation, make lowercase\n",
        "        normalized_tag = re.sub(r'[^\\w\\s]', '', tag.lower())  # Remove punctuation, make lowercase\n",
        "\n",
        "        # Check if the tag or its key words are present in the description\n",
        "        return normalized_tag in normalized_description or any(word in normalized_description for word in normalized_tag.split())\n",
        "\n",
        "    # Clean and format tags\n",
        "    def clean_and_format_tags(raw_keywords, description):\n",
        "        \"\"\"\n",
        "        Clean and format the raw keywords/tags based on relevance and formatting rules.\n",
        "        \"\"\"\n",
        "        tags = []\n",
        "        seen_tags = set()\n",
        "        for tag in raw_keywords:\n",
        "            # Normalize tag: lowercase, remove punctuation\n",
        "            tag = tag.strip().lower().replace(\";\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
        "\n",
        "            # Include only unique, relevant, and properly formatted tags\n",
        "            if tag and tag not in seen_tags and is_relevant_tag(tag, description):\n",
        "                seen_tags.add(tag)\n",
        "                tags.append(tag.capitalize())  # Capitalize the first letter\n",
        "\n",
        "        # Limit to 5 tags and join with commas\n",
        "        return \", \".join(tags[:5])\n",
        "\n",
        "    # Process data function\n",
        "    def process_data(data):\n",
        "        processed_data = {}\n",
        "        for filename, description in data.items():\n",
        "            # Clean up the description: remove / and styles, capitalize sentences\n",
        "            cleaned_description = \". \".join([part.strip().capitalize() for part in description.split(\"/\") if part.strip()])\n",
        "\n",
        "            # Generate SEO-friendly title\n",
        "            seo_title = \"Photorealistic Woman in Urban Autumn Setting | High-Resolution Artwork\" if \"woman\" in cleaned_description.lower() else (\n",
        "                \"Lifelike White Cat with Bright Green Eyes | Detailed Digital Illustration\" if \"cat\" in cleaned_description.lower() else \"High-Quality Pet Grooming Photography | Nature Illustration\"\n",
        "            )\n",
        "            cta_text = \"❤️ Discover this stunning artwork and bring elegance to your space today!\" if \"woman\" in cleaned_description.lower() else (\n",
        "                \"💚 Admire the charm of this adorable feline masterpiece and make it yours now!\" if \"cat\" in cleaned_description.lower() else \"🐾 Explore the beauty of pet grooming through this incredible photography!\"\n",
        "            )\n",
        "\n",
        "            # Rewrite description using language model\n",
        "            rewritten_description = clean_and_rewrite_description(cleaned_description)\n",
        "\n",
        "            # Extract keywords/tags using bloomberg/KeyBART and clean them\n",
        "            try:\n",
        "                raw_keywords = keyword_extractor(rewritten_description, max_length=50, truncation=True)[0]['generated_text'].split(\", \")\n",
        "\n",
        "                # Clean and filter tags based on relevance and formatting\n",
        "                tags_str = clean_and_format_tags(raw_keywords, rewritten_description)\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting keywords for {filename}: {e}\")\n",
        "                tags_str = \"\"  # Fallback to empty tags if extraction fails\n",
        "\n",
        "            # Add an empty field for the posted date\n",
        "            processed_data[filename] = {\n",
        "                \"seo_title\": seo_title,\n",
        "                \"description\": rewritten_description,\n",
        "                \"cta\": cta_text,\n",
        "                \"tags\": tags_str,  # Save tags as a comma-separated string\n",
        "                \"processing_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                \"posted_date\": \"\"  # Empty field for when the image is posted\n",
        "            }\n",
        "\n",
        "        return processed_data\n",
        "\n",
        "    # Save processed data to JSON file\n",
        "    def save_to_json(data, file_path):\n",
        "        try:\n",
        "            with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "                json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
        "            print(f\"JSON file saved successfully at: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving JSON file: {e}\")\n",
        "\n",
        "    # Main processing logic\n",
        "    processed_data = process_data(data)\n",
        "    OUTPUT_FILE_PATH = f\"{OUTPUT_DIRECTORY}/processed_art_data.json\"\n",
        "    save_to_json(processed_data, OUTPUT_FILE_PATH)\n",
        "\n",
        "    print(f\"Processing completed. Output saved to: {OUTPUT_FILE_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
